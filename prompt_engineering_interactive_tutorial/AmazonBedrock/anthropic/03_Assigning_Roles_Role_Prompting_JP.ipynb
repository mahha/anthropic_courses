{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Assigning Roles (Role Prompting)\n",
    "\n",
    "（第3章：役割を与える（ロールプロンプティング））\n",
    "\n",
    "- [レッスン](#lesson)\n",
    "- [演習](#exercises)\n",
    "- [例のプレイグラウンド](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "次のセットアップセルを実行して、APIキーの読み込みと `get_completion` ヘルパー関数の準備を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic --quiet\n",
    "\n",
    "# Import the hints module from the utils package\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import hints\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "%store -r MODEL_NAME\n",
    "%store -r AWS_REGION\n",
    "\n",
    "client = AnthropicBedrock(aws_region=AWS_REGION)\n",
    "\n",
    "def get_completion(prompt, system=''):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        system=system\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "Claude は、あなたが伝えたこと以外の文脈を持たない、という話を続けます。ときには、Claude に **特定の役割（必要な背景情報を含む）を演じさせる** ことが重要になります。これは **ロールプロンプティング（role prompting）** とも呼ばれます。役割の文脈は、詳しければ詳しいほど効果的です。\n",
    "\n",
    "**役割で Claude をプライミング（事前設定）すると、さまざまな分野で性能が向上** することがあります。文章作成、コーディング、要約など幅広く有効で、人間が『○○のつもりで考えて』と言われると助けになるのと似ています。ロールプロンプティングは、Claude の応答のスタイル・トーン・話し方も変えられます。\n",
    "\n",
    "**Note:** ロールプロンプティングは、システムプロンプトでも User メッセージの一部としても行えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "次の例では、ロールプロンプティングなしの場合、スケートボードについて1文で意見を求めても、Claude は **素直で装飾のない回答** を返します。\n",
    "\n",
    "しかし、Claude に『猫』の役割を与えると、視点が変わり、**トーン／スタイル／内容が役割に合わせて適応** します。\n",
    "\n",
    "**Note:** 追加のテクニックとして、Claude に **想定読者（audience）** を伝える方法もあります。たとえば「You are a cat」と「you are a cat talking to a crowd of skateboarders」では、かなり違う応答になります。\n",
    "\n",
    "まずは、システムプロンプトでロール指定をしない場合の例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じユーザー質問に対して、ロールプロンプティングを入れた例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロールプロンプティングは、特定の文体を真似させたり、特定の声色で話させたり、回答の難易度や複雑さを調整したりするのに使えます。さらに **数学や論理のタスクが得意になる** こともあります。\n",
    "\n",
    "たとえば次の例には明確な正解（Yes）があります。しかし、この状態の Claude は誤って『情報が足りない』と判断します（実際は足りています）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、Claude を **論理問題を解くボット** としてプライミングしたらどうでしょう？ 回答はどう変わるでしょうか。\n",
    "\n",
    "この新しい役割を与えると、Claude は正解に到達します（ただし、理由付けは必ずしも完璧ではありません）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** このコースを通じて学ぶように、同じような結果を得るための **プロンプトエンジニアリング手法は数多く存在** します。どの手法を使うかはあなた次第です。ぜひ **試行錯誤して、自分のスタイル** を見つけてください。\n",
    "\n",
    "上の内容を変えずにレッスンのプロンプトだけ試したい場合は、ノートブック末尾の [**Example Playground**](#example-playground) を利用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 3.1 - Math Correction](#exercise-31---math-correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 - Math Correction\n",
    "場合によっては、**Claude は数学（たとえ簡単なものでも）でつまずく** ことがあります。下の例では、2行目に明らかな計算ミスがあるにもかかわらず、Claude はその解答を『正しい』と評価してしまいます。なお、段階的に見れば Claude 自体はミスに気づいているのに、全体として『誤り』だと結論づけません。\n",
    "\n",
    "`PROMPT` と / または `SYSTEM_PROMPT` を修正して、Claude が解答を `incorrectly`（誤り）と評価するようにしてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt - if you don't want to use a system prompt, you can leave this variable set to an empty string\n",
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this equation solved correctly below?\n",
    "\n",
    "2x - 3 = 9\n",
    "2x = 6\n",
    "x = 3\"\"\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    if \"incorrect\" in text or \"not correct\" in text.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ ヒントが欲しい場合は、次のセルを実行してください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_3_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "ここまでの演習をすべて解けたら、次の章に進む準備ができています。Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "このエリアでは、このレッスンで示したプロンプト例を自由に試し、プロンプトを調整して Claude の応答がどう変わるかを観察できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
