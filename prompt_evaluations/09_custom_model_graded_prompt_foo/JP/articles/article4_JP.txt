畳み込みニューラル ネットワーク (CNN) は、フィルター (またはカーネル) 最適化を通じて機能を独自に学習する、正則化されたタイプのフィードフォワード ニューラル ネットワークです。初期のニューラル ネットワークのバックプロパゲーション中に見られた勾配の消失と勾配の爆発は、より少ない接続で正規化された重みを使用することによって防止されます。[1][2]たとえば、全結合層の各ニューロンについて、100 × 100 ピクセルのサイズの画像を処理するには 10,000 の重みが必要になります。ただし、カスケード コンボリューション (または相互相関) カーネルを適用すると、5x5 サイズのタイルを処理するのに必要なニューロンは 25 個だけです。[5][6]上位層の特徴は、下位層の特徴と比較して、より広いコンテキスト ウィンドウから抽出されます。

次の場所にアプリケーションがあります。

画像およびビデオの認識[7]
推奨システム、[8]
画像分類、
画像のセグメンテーション、
医療画像解析、
自然言語処理、[9]
脳とコンピューターのインターフェース[10]、および
金融時系列 [11]
CNN は、シフト不変または空間不変の人工ニューラル ネットワーク (SIANN) としても知られており、入力特徴に沿ってスライドし、特徴マップとして知られる変換等変応答を提供する畳み込みカーネルまたはフィルターの共有重みアーキテクチャに基づいています。[12][13]直観に反しますが、ほとんどの畳み込みニューラル ネットワークは、入力にダウンサンプリング操作を適用するため、変換に対して不変ではありません [14]。

フィードフォワード ニューラル ネットワークは通常、完全に接続されたネットワークです。つまり、ある層の各ニューロンは次の層のすべてのニューロンに接続されています。これらのネットワークの「完全な接続」により、データが過剰適合する傾向があります。正則化または過学習の防止の一般的な方法には、トレーニング中のパラメータにペナルティを与える (重みの減衰など) または接続性をトリミングする (接続のスキップ、ドロップアウトなど) ことが含まれます。また、堅牢なデータセットにより、CNN が、母集団が不十分なセットのバイアスではなく、特定のデータセットを特徴付ける一般化された原則を学習する可能性も高まります [15]。

畳み込みネットワークは、ニューロン間の接続パターンが動物の視覚野の構成に似ているという生物学的プロセスにインスピレーションを得て作られました[16][17][18][19]。個々の皮質ニューロンは、受容野として知られる視野の限られた領域でのみ刺激に反応します。異なるニューロンの受容野は部分的に重なり、視野全体をカバーします。

CNN は、他の画像分類アルゴリズムと比較して、比較的少量の前処理を使用します。これは、従来のアルゴリズムではこれらのフィルターが手動で設計されるのに対し、ネットワークは自動学習を通じてフィルター (またはカーネル) を最適化する方法を学習することを意味します。事前の知識や特徴抽出における人間の介入から独立していることは、大きな利点です。[誰にとって?]

建築

LeNet と AlexNet の畳み込み、プーリング、および密な層の比較
(AlexNet の画像サイズは 224×224×3 ではなく 227×227×3 にする必要があるため、計算は正しくなります。元の論文では異なる数値が記載されていましたが、テスラのコンピューター ビジョン責任者であるアンドレイ カルパシー氏は、227×227×3 であるべきだと述べました (アレックスは 224×224×3 とした理由について説明していないと述べました)。次の畳み込みはストライド付き 11×11 である必要があります。 4: 55×55×96 (54×54×96 の代わりに) たとえば、次のように計算されます: [(入力幅 227 - カーネル幅 11) / ストライド 4] + 1 = [(227 - 11) / 4] + 1 = 55。カーネル出力は長さと幅が同じであるため、その面積は 55×55 です。
詳細は「レイヤー (深層学習)」を参照
畳み込みニューラル ネットワークは、入力層、隠れ層、出力層で構成されます。畳み込みニューラル ネットワークでは、隠れ層には畳み込みを実行する 1 つ以上の層が含まれます。通常、これには、コンボリューション カーネルと層の入力行列の内積を実行する層が含まれます。この積は通常フロベニウスの内積であり、その活性化関数は通常 ReLU です。畳み込みカーネルが層の入力行列に沿ってスライドすると、畳み込み演算によって特徴マップが生成され、それが次の層の入力に寄与します。これに、プーリング層、完全接続層、正規化層などの他の層が続きます。ここで、畳み込みニューラル ネットワークがマッチド フィルターにどれほど近いかに注目する必要があります。[20]

畳み込み層
CNN では、入力は次の形状を持つテンソルです。

(入力数) × (入力高さ) × (入力幅) × (入力チャンネル数)

畳み込み層を通過した後、画像は次の形状を持つ特徴マップ (アクティベーション マップとも呼ばれます) に抽象化されます。

(入力数) × (特徴マップの高さ) × (特徴マップの幅) × (特徴マップのチャネル)。

畳み込み層は入力を畳み込み、その結果を次の層に渡します。これは、特定の刺激に対する視覚野のニューロンの反応に似ています。各畳み込みニューロンは、その受容野に対してのみデータを処理します。


1D 畳み込みニューラル ネットワークのフィードフォワードの例
完全に接続されたフィードフォワード ニューラル ネットワークを使用して特徴を学習し、データを分類することはできますが、このアーキテクチャは一般に、各ピクセルが関連する入力特徴であるため、大量のニューロンが必要となる大きな入力 (高解像度画像など) には非現実的です。サイズ 100 × 100 の画像の全結合層には、2 番目の層の各ニューロンに 10,000 の重みがあります。畳み込みは自由なパラメータの数を減らし、ネットワークをより深くすることができます。[5]たとえば、それぞれが同じ共有重みを持つ 5 × 5 のタイリング領域を使用する場合、必要なニューロンは 25 個だけです。より少ないパラメータに対して正規化された重みを使用すると、初期のニューラル ネットワークのバックプロパゲーション中に見られた勾配の消失や勾配の爆発の問題が回避されます。[1][2]

処理を高速化するために、標準の畳み込み層を深さ方向の分離可能な畳み込み層に置き換えることができます[22]。これは、深さ方向の畳み込みとそれに続く点方向の畳み込みに基づいています。深さ方向の畳み込みは、入力テンソルの各チャネルに個別に適用される空間畳み込みですが、点方向の畳み込みは、次の使用に制限された標準の畳み込みです。 
1
×
1
{\displaystyle 1\times 1} カーネル。

プーリング層
畳み込みネットワークには、従来の畳み込み層に加えて、ローカルおよび/またはグローバル プーリング層が含まれる場合があります。プーリング層は、ある層のニューロン クラスターの出力を次の層の単一のニューロンに結合することにより、データの次元を削減します。ローカル プーリングは小さなクラスターを結合し、2 × 2 などのタイル サイズが一般的に使用されます。グローバル プーリングは、特徴マップのすべてのニューロンに作用します。[23][24]一般的に使用されているプーリングには、最大と平均の 2 つのタイプがあります。最大プーリングでは、特徴マップ内のニューロンの各ローカル クラスターの最大値が使用されます [25][26]。一方、平均プーリングでは平均値が使用されます。

完全に接続された層
完全に接続された層は、ある層のすべてのニューロンを別の層のすべてのニューロンに接続します。これは、従来の多層パーセプトロン ニューラル ネットワーク (MLP) と同じです。平坦化されたマトリックスは、完全に接続された層を通過して画像を分類します。

受容野
ニューラル ネットワークでは、各ニューロンは前の層のいくつかの場所から入力を受け取ります。畳み込み層では、各ニューロンは、ニューロンの受容野と呼ばれる前の層の制限された領域のみから入力を受け取ります。通常、領域は正方形です (例: 5 x 5 ニューロン)。一方、完全に接続された層では、受容野は前の層全体になります。したがって、各畳み込み層では、各ニューロンは前の層よりも入力内のより広い領域から入力を受け取ります。これは、ピクセルの値とその周囲のピクセルの値を考慮した畳み込みを何度も適用するためです。拡張レイヤーを使用する場合、受容野のピクセル数は一定のままですが、複数のレイヤーの効果を組み合わせると、受容野の寸法が大きくなるにつれて、受容野の人口がよりまばらになります。

受容野のサイズを必要に応じて操作するには、標準の畳み込み層の代替手段がいくつかあります。たとえば、アトラスまたは拡張畳み込み[27][28]は、可視領域と盲領域をインターリーブすることにより、パラメータの数を増やすことなく受容野サイズを拡張します。さらに、単一の拡張畳み込み層は複数の拡張率を持つフィルターを構成できるため [29]、可変の受容野サイズを持つことができます。

重み
ニューラル ネットワーク内の各ニューロンは、前の層の受容野から受け取った入力値に特定の関数を適用することによって出力値を計算します。入力値に適用される関数は、重みのベクトルとバイアス (通常は実数) によって決定されます。学習は、これらのバイアスと重みを繰り返し調整することで構成されます。

重みとバイアスのベクトルはフィルターと呼ばれ、入力の特定の特徴 (特定の形状など) を表します。 CNN の際立った特徴は、多くのニューロンが同じフィルターを共有できることです。これにより、各受容野が独自のバイアスとベクトル重み付けを持つのではなく、そのフィルターを共有するすべての受容野にわたって単一のバイアスと単一の重みベクトルが使用されるため、メモリ フットプリントが削減されます。[30]

歴史
CNN は、生物の脳が視覚処理を実現する方法とよく比較されます [31]。

視覚野の受容野
1950 年代と 1960 年代のフーベルとヴィーゼルの研究では、猫の視覚野には、視野の小さな領域に個別に反応するニューロンが含まれていることが示されました。目が動いていない場合、視覚刺激が単一のニューロンの発火に影響を与える視覚空間の領域は、その受容野として知られています。隣接する細胞には、類似した重複する受容野があります。受容野のサイズと位置は、視覚空間の完全な地図を形成するために、皮質全体にわたって体系的に変化します。[要出典] 各半球の皮質は、対側の視野を表します。[要出典]

彼らの 1968 年の論文では、脳内の 2 つの基本的な視覚細胞タイプが特定されました。[17]

単純な細胞。その出力は、受容野内で特定の向きを持つ直線エッジによって最大化されます。
複雑な細胞。より大きな受容野を持ち、その出力はフィールド内のエッジの正確な位置に影響されません。
Hubel と Wiesel は、パターン認識タスクで使用するこれら 2 種類の細胞のカスケード モデルも提案しました。[33][32]

Neocognitron、CNN アーキテクチャの起源
「ネオコグニトロン」[16]は1980年に福島邦彦によって導入された[18][26][34]。これは、前述のフーベルとヴィーゼルの研究に触発されました。 Neocognitron では、次の 2 つの基本的なタイプのレイヤーが導入されました。

「S層」: 後に畳み込み層として知られる共有重み受容野層。これには、受容野が前の層のパッチをカバーするユニットが含まれます。共有重み受容野グループ (ネオコグニトロン用語では「プレーン」) はフィルターと呼ばれることが多く、通常、レイヤーにはそのようなフィルターがいくつかあります。
「C層」: 受容野が以前の畳み込み層のパッチをカバーするユニットを含むダウンサンプリング層。このようなユニットは通常、パッチ内のユニットのアクティベーションの加重平均を計算し、やや大きなパッチからプールされ、レイヤー内のさまざまなフィルター全体にプールされた抑制 (分割正規化) を適用し、飽和アクティベーション関数を適用します。パッチの重みは負ではないため、元のネオコグニトロンではトレーニングできません。ダウンサンプリングと競合抑制は、オブジェクトが移動している場合でも、ビジュアル シーン内のフィーチャとオブジェクトを分類するのに役立ちます。
1969 年に福島は ReLU (修正線形単位) 活性化関数を導入しました [35] [36]。すべての重みが負ではなかったため、彼のネオコグニトロンでは使用されませんでした。代わりに側方抑制が使用されました。整流器は、CNN およびディープ ニューラル ネットワーク全般にとって最も一般的な活性化関数となっています [37]。

クレセセプトロンと呼ばれるネオコグニトロンの変形では、抑制と飽和による福島の空間平均化を使用する代わりに、J. Weng et al. 1993 年に、ダウンサンプリング ユニットがパッチ内のユニットのアクティベーションの最大値を計算する max-pooling と呼ばれる方法を導入しました。 Max-pooling は、最新の CNN でよく使用されます。[39]

ネオコグニトロンの重みを訓練するために、数十年にわたっていくつかの教師あり学習アルゴリズムと教師なし学習アルゴリズムが提案されてきました[16]。しかし、今日では、CNN アーキテクチャは通常、バックプロパゲーションを通じてトレーニングされます。

ネオコグニトロンは、複数のネットワーク位置にあるユニットが重みを共有することを必要とする最初の ANN であり、これは CNN の特徴です。

時間の畳み込み
「畳み込み」という用語が初めてニューラル ネットワークに登場したのは、1987 年の第 1 回神経情報処理システム会議における本間俊輝、レス アトラス、ロバート マークス II による論文でした。彼らの論文は、乗算を時間内畳み込みに置き換え、本質的にシフト不変性を提供し、フィルターの信号処理概念によって動機づけられ、より直接的に結びつけ、音声認識タスクでそれを実証しました。[6]彼らはまた、データ学習可能なシステムとして、重みの反転が最終的に学習された関数に影響を与えないため、畳み込みは本質的に相関と同等であると指摘しました (「便宜上、* を畳み込みではなく相関として示します。a(t) を b(t) と畳み込むことは、a(-t) と b(t) を相関させることと同等であることに注意してください。」[6]。最近の CNN 実装では、通常、相関関係を実行し、ここで行ったように、便宜上、それを畳み込みと呼びます。

時間遅延ニューラルネットワーク
時間遅延ニューラル ネットワーク (TDNN) は、1987 年に Alex Waibel らによって導入されました。音素認識用であり、シフト不変性を達成した最初の畳み込みネットワークの 1 つでした。[40] TDNN は、データの時間軸に沿って畳み込みが実行される 1 次元畳み込みニューラル ネットワークです。これは、バックプロパゲーションを使用した勾配降下によるトレーニングと組み合わせて重み共有を利用した最初の CNN です。[41]したがって、ネオコグニトロンと同様にピラミッド構造を使用しながら、局所的な重みではなく全体的な重みの最適化を実行しました。[40]

TDNN は、時間次元に沿って重みを共有する畳み込みネットワークです。[42]これらにより、音声信号を時間不変に処理できるようになります。 1990 年に、Hampshire と Waibel は 2 次元の畳み込みを実行するバリアントを導入しました [43]。これらの TDNN はスペクトログラム上で動作するため、結果として得られる音素認識システムは、ネオコグニトロンによって処理された画像と同様に、時間と周波数の両方のシフトに対して不変でした。

TDNN により、遠距離音声認識のパフォーマンスが向上しました。[44]

勾配降下法で訓練された CNN による画像認識
デンカーら。 (1989) 手書きの郵便番号番号を認識する 2 次元 CNN システムを設計しました。[45]しかし、関係する畳み込みのカーネル係数を決定するための効率的なトレーニング方法がなかったため、すべての係数を手間をかけて手作業で設計する必要がありました。[46]

Waibel らによる 1 次元 CNN のトレーニングの進歩に続いて、 (1987)、Yann LeCun 他。 (1989)[46]は逆伝播を使用して、手書きの数字の画像から直接畳み込みカーネル係数を学習しました。したがって、学習は完全に自動化され、手動による係数設計よりも優れたパフォーマンスが得られ、より広範囲の画像認識問題と画像タイプに適していました。魏張ら。 (1988)[12][13] は、逆伝播を使用して、アルファベット認識用の CNN の畳み込みカーネルをトレーニングしました。このモデルは、1990 年代初頭に CNN という名前が作られるまでは、シフト不変パターン認識ニューラル ネットワークと呼ばれていました。魏張ら。また、最後の完全に接続された層を持たない同じ CNN を、医療画像オブジェクトのセグメンテーション (1991 年) [47] とマンモグラムでの乳がん検出 (1994 年) に適用しました。

このアプローチは、現代のコンピューター ビジョンの基礎となりました。

最大プーリング
1990 年に山口ら。は、特定の領域の最大値を計算して伝播する固定フィルタリング操作である最大プーリングの概念を導入しました。彼らは、TDNN と最大プーリングを組み合わせて話者に依存しない分離単語認識システムを実現することでこれを実現しました。[25]彼らのシステムでは、単語ごとに複数の TDNN を、音節ごとに 1 つずつ使用しました。入力信号に対する各 TDNN の結果は、最大プーリングを使用して結合され、プーリング層の出力が実際の単語分類を実行するネットワークに渡されました。

ルネット-5
詳細は「ルネット」を参照
LeNet-5 は、LeCun らによる先駆的な 7 レベルの畳み込みネットワークです。 1995 年に [49] は、32x32 ピクセルの画像でデジタル化された小切手 (イギリス英語: cheques) の手書き番号を分類しました。高解像度の画像を処理するには、畳み込みニューラル ネットワークのより多くの層が必要となるため、この技術はコンピューティング リソースの可用性によって制限されます。

他の商用礼金額読み取りシステムよりも優れていました（1995年時点）。このシステムは NCR の小切手読み取りシステムに統合され、1996 年 6 月からアメリカのいくつかの銀行に導入され、1 日あたり数百万枚の小切手を読み取りました。[50]

シフト不変ニューラル ネットワーク
シフト不変ニューラル ネットワークは、Wei Zhang らによって提案されました。 1988 年の画像文字認識用。[12][13]これは、画像フィーチャ レイヤーと最後に完全に接続されたレイヤーの間の畳み込み相互接続のみを保持することによって修正された Neocognitron です。モデルはバックプロパゲーションを使用してトレーニングされました。トレーニング アルゴリズムは 1991 年にさらに改良され [51]、汎化能力が向上しました。モデル アーキテクチャは、最後に完全に接続された層を削除することによって変更され、医療画像のセグメンテーション (1991 年) [47] およびマンモグラムでの乳がんの自動検出 (1994 年) に適用されました。

1988 年には、デコンボリューションによる一次元筋電図の畳み込み信号の分解に適用するための、別の畳み込みベースの設計が提案されました [52]。この設計は 1989 年に他のデコンボリューションベースの設計に変更されました [53] [54]。

ニューラル抽象化ピラミッド
神経抽象化ピラミッド
ニューラル抽象化ピラミッド
畳み込みニューラル ネットワークのフィードフォワード アーキテクチャは、横方向接続とフィードバック接続によってニューラル抽象化ピラミッド [55] で拡張されました。結果として得られる再帰畳み込みネットワークにより、コンテキスト情報を柔軟に組み込んで、局所的なあいまいさを繰り返し解決できます。以前のモデルとは対照的に、セマンティック セグメンテーション、画像再構成、オブジェクト位置特定タスクなどのために、最高解像度の画像のような出力が生成されました。

GPUの実装
CNN は 1980 年代に発明されましたが、2000 年代の画期的な進歩には、グラフィックス プロセッシング ユニット (GPU) での高速実装が必要でした。

2004 年に、K. S. Oh と K. Jung によって、標準のニューラル ネットワークが GPU で大幅に高速化できることが示されました。彼らの実装は、CPU 上の同等の実装よりも 20 倍高速でした。[56] 2005 年には、別の論文でも機械学習における GPGPU の価値が強調されました [57]。

CNN の最初の GPU 実装は、2006 年に K. Chellapilla らによって説明されました。彼らの実装は、CPU 上の同等の実装よりも 4 倍高速でした。[58]同時期に、GPU は深い信念ネットワークの教師なしトレーニングにも使用されました。[59][60][61][62]

2010 年に、Dan Ciresan ら。 IDSIA では、GPU 上でディープ フィードフォワード ネットワークをトレーニングしました。[63] 2011 年に、彼らはこれを CNN に拡張し、CPU のトレーニングと比較して 60 高速化しました。[23] 2011 年、ネットワークは画像認識コンテストで優勝し、初めて超人的なパフォーマンスを達成しました。[64]その後、彼らはさらに多くのコンテストで優勝し、いくつかのベンチマークで最先端の成績を達成しました[65][39][26]。

その後、Alex Krizhevsky らによる同様の GPU ベースの CNN、AlexNet が登場しました。 ImageNet 大規模視覚認識チャレンジ 2012 で優勝しました。[66]これは AI ブームの初期の触媒となる出来事でした。

Microsoft による 100 層を超える非常に深い CNN が ImageNet 2015 コンテストで優勝しました。[67]

インテル Xeon Phi の実装
GPU を使用した CNN のトレーニングと比較して、Intel Xeon Phi コプロセッサーにはあまり注目が払われませんでした。[68]注目すべき開発は、Controlled Hogwild with Arbitrary Order of Synchronization (CHAOS) と呼ばれる、Intel Xeon Phi 上で畳み込みニューラル ネットワークをトレーニングするための並列化手法です。[69] CHAOS は、インテル Xeon Phi で利用可能なスレッドレベルと SIMD レベルの両方の並列処理を利用します。

特徴
以前は、画像認識には従来の多層パーセプトロン (MLP) モデルが使用されていました。[例が必要] ただし、ノード間の完全な接続は次元の呪いを引き起こし、高解像度の画像では計算的に処理できませんでした。 RGB カラー チャネルを含む 1000 × 1000 ピクセルの画像には、完全に接続されたニューロンごとに 300 万の重みがあり、大規模に効率的に処理するには多すぎます。


3次元に配置されたCNNレイヤー
たとえば、CIFAR-10 では、画像のサイズは 32×32×3 (幅 32、高さ 32、カラー チャネル 3) のみであるため、通常のニューラル ネットワークの最初の隠れ層にある完全に接続された 1 つのニューロンの重みは 32*32*3 = 3,072 になります。ただし、200×200 の画像では、200*200*3 = 120,000 の重みを持つニューロンが生成されます。

また、このようなネットワーク アーキテクチャはデータの空間構造を考慮しておらず、遠く離れた入力ピクセルを互いに近いピクセルと同じように扱います。これは、計算的にも意味的にも、グリッド トポロジを持つデータ (画像など) の参照の局所性を無視します。したがって、ニューロンの完全な接続は、空間的に局所的な入力パターンによって支配される画像認識などの目的にとっては無駄です。

畳み込みニューラル ネットワークは多層パーセプトロンの変形であり、視覚野の動作をエミュレートするように設計されています。これらのモデルは、自然画像に存在する強力な空間的局所相関を利用することで、MLP アーキテクチャによってもたらされる課題を軽減します。 MLP とは対照的に、CNN には次のような際立った特徴があります。

ニューロンの 3D ボリューム。 CNN の層には、幅、高さ、深さの 3 次元に配置されたニューロンがあります。[70]畳み込み層内の各ニューロンは、その前の層の、受容野と呼ばれる小さな領域にのみ接続されます。局所的に接続された層と完全に接続された層の両方がスタックされて、CNN アーキテクチャを形成します。
ローカル接続: 受容野の概念に従い、CNN は隣接する層のニューロン間にローカル接続パターンを強制することで空間的局所性を利用します。したがって、このアーキテクチャは、学習された「フィルター」が空間的にローカルな入力パターンに対して最も強い応答を生成することを保証します。このようなレイヤーを多数積み重ねると、非線形フィルターがますますグローバルになり (つまり、ピクセル空間のより大きな領域に応答する)、ネットワークが最初に入力の小さな部分の表現を作成し、次にそれらからより大きな領域の表現を組み立てます。
共有重み: CNN では、各フィルターが視野全体にわたって複製されます。これらの複製されたユニットは同じパラメータ化 (重みベクトルとバイアス) を共有し、特徴マップを形成します。これは、特定の畳み込み層内のすべてのニューロンが、特定の応答フィールド内の同じ特徴に応答することを意味します。この方法でユニットを複製すると、結果として得られるアクティベーション マップが視野内の入力フィーチャの位置のシフトの下で等変になることが可能になります。つまり、レイヤーのストライドが 1 であると仮定すると、並進等変性が付与されます。[71]
プーリング: CNN のプーリング層では、特徴マップは長方形のサブ領域に分割され、各長方形内の特徴は、通常は平均値または最大値を取得することによって、単一の値に個別にダウンサンプリングされます。特徴マップのサイズを縮小することに加えて、プーリング操作により、そこに含まれる特徴にある程度の局所的な並進不変性が付与され、CNN が位置の変動に対してより堅牢になることが可能になります。[14]
これらの特性を組み合わせることで、CNN は視覚の問題についてより適切な一般化を達成できるようになります。重み共有により、学習される自由パラメータの数が大幅に減少するため、ネットワークを実行するためのメモリ要件が軽減され、より大規模で強力なネットワークのトレーニングが可能になります。

ビルディングブロック

このセクションには検証のため追加の引用が必要です。このセクションに信頼できる情報源への引用を追加して、記事の改善にご協力ください。出典のない素材は異議を申し立てられ、削除される場合があります。 (2017 年 6 月) (このメッセージを削除する方法とタイミングについてはこちらをご覧ください)
CNN アーキテクチャは、微分可能な関数を通じて入力ボリュームを出力ボリューム (クラス スコアの保持など) に変換する個別のレイヤーのスタックによって形成されます。いくつかの異なるタイプのレイヤーが一般的に使用されます。これらについては、以下でさらに説明します。


畳み込み層のニューロン (青)、受容野 (赤) に接続されています。
畳み込み層

畳み込みを実行する実際の例。畳み込みのストライドは 1、ゼロ パディング、カーネル サイズは 3 行 3 列です。畳み込みカーネルは離散ラプラシアン演算子です。
畳み込み層は、CNN の中核となる構成要素です。この層のパラメーターは、一連の学習可能なフィルター (またはカーネル) で構成されており、受容野は小さいですが、入力ボリュームの深さ全体に広がります。順方向パス中に、各フィルターは入力ボリュームの幅と高さにわたって畳み込まれ、フィルター エントリと入力の間のドット積が計算され、そのフィルターの 2 次元活性化マップが生成されます。その結果、ネットワークは、入力内のある空間位置で特定のタイプの特徴を検出したときにアクティブになるフィルターを学習します。[72][注 1]。

すべてのフィルターのアクティベーション マップを深さ次元に沿って積み重ねると、畳み込み層の完全な出力ボリュームが形成されます。したがって、出力ボリューム内のすべてのエントリは、入力内の小さな領域を調べるニューロンの出力として解釈することもできます。アクティベーション マップの各エントリは、フィルターを定義する同じパラメーターのセットを使用します。

自己教師あり学習は、高マスク比のスパース パッチとグローバル応答正規化層を使用することで、畳み込み層での使用に適応されています。[要出典]

ローカル接続

典型的な CNN アーキテクチャ
画像などの高次元入力を扱う場合、そのようなネットワーク アーキテクチャではデータの空間構造が考慮されていないため、ニューロンを前のボリュームのすべてのニューロンに接続することは現実的ではありません。畳み込みネットワークは、隣接する層のニューロン間にまばらなローカル接続パターンを強制することにより、空間的なローカル相関を利用します。つまり、各ニューロンは入力ボリュームの小さな領域にのみ接続されます。

この接続の範囲は、ニューロンの受容野と呼ばれるハイパーパラメーターです。接続は空間内で (幅と高さに沿って) 局所的ですが、常に入力ボリュームの深さ全体に沿って広がります。このようなアーキテクチャにより、学習済み (イギリス英語: learnt) フィルターが空間的にローカルな入力パターンに対して最も強い応答を生成することが保証されます。

空間配置
3 つのハイパーパラメータ (深さ、ストライド、パディング サイズ) は、畳み込み層の出力ボリュームのサイズを制御します。

出力ボリュームの深さは、入力ボリュームの同じ領域に接続するレイヤー内のニューロンの数を制御します。これらのニューロンは、入力内のさまざまな特徴に対して活性化することを学習します。たとえば、最初の畳み込み層が生の画像を入力として受け取る場合、さまざまな向きのエッジまたは色の塊の存在下で、深さ次元に沿った異なるニューロンが活性化する可能性があります。
ストライドは、幅と高さの周りの深さの列がどのように割り当てられるかを制御します。ストライドが 1 の場合、フィルターを一度に 1 ピクセルずつ移動します。これにより、カラム間の受容野が重なり合い、出力量が大きくなります。任意の整数の場合 
S
>
0
、
{\textstyle S>0,} ストライド S は、フィルターが出力ごとに一度に S 単位で変換されることを意味します。実際には、 
S
≥
3
{\textstyle S\geq 3} はまれです。ストライドが大きいほど、受容野の重なりが小さくなり、出力ボリュームの空間的寸法が小さくなります。[73]
場合によっては、入力ボリュームの境界にゼロ (または領域の平均などの他の値) を入力に埋め込むと便利です。このパディングのサイズは 3 番目のハイパーパラメータです。パディングは、出力ボリュームの空間サイズを制御します。特に、入力ボリュームの空間サイズを正確に保存することが望ましい場合があります。これは一般に「同じ」パディングと呼ばれます。

パディング条件の 3 つの例。レプリケーション条件は、外側のピクセルが内側の最も近いピクセルでパディングされることを意味します。反射パディングは、外側のピクセルが内側のピクセルでパディングされ、画像の境界を越えて反射されます。円形のパディングは、外側のピクセルが画像の反対側に回り込む場所です。
出力ボリュームの空間サイズは、入力ボリュームのサイズの関数です。 
W
{\displaystyle W}、カーネルフィールドのサイズ 
K
畳み込み層ニューロンの {\displaystyle K}、ストライド 
S
{\displaystyle S}、およびゼロパディングの量 
P
境界上の {\displaystyle P}。特定のボリュームに「収まる」ニューロンの数は次のようになります。

W
−
K
+
2
P
S
+
1.
{\displaystyle {\frac {W-K+2P}{S}}+1.}
この数値が整数でない場合、ストライドは不正確であり、ニューロンをタイル状に並べて入力ボリューム全体に対称的にフィットさせることができません。一般に、ゼロパディングを次のように設定します。 
P
=
(
K
−
1
)
/
2
{\textstyle P=(K-1)/2} 歩幅が 
S
=
1
{\displaystyle S=1} は、入力ボリュームと出力ボリュームが空間的に同じサイズになるようにします。ただし、前の層のすべてのニューロンを使用する必要があるとは限りません。たとえば、ニューラル ネットワークの設計者は、パディングの一部だけを使用することを決定する場合があります。

パラメータの共有
畳み込み層では、自由パラメーターの数を制御するためにパラメーター共有スキームが使用されます。これは、パッチ フィーチャがある空間位置での計算に役立つ場合、他の位置での計算にも役立つはずであるという前提に基づいています。深度の単一の 2 次元スライスを深度スライスとして表すと、各深度スライス内のニューロンは同じ重みとバイアスを使用するように制約されます。

単一の深度スライス内のすべてのニューロンは同じパラメーターを共有するため、畳み込み層の各深度スライス内の順方向パスは、ニューロンの重みと入力ボリュームの畳み込みとして計算できます。[nb 2] したがって、重みのセットを入力と畳み込まれるフィルター (またはカーネル) と呼ぶのが一般的です。この畳み込みの結果はアクティベーション マップであり、異なるフィルターごとのアクティベーション マップのセットが深さの次元に沿ってスタックされて、出力ボリュームが生成されます。パラメータの共有は、CNN アーキテクチャの翻訳の不変性に貢献します。[14]

場合によっては、パラメーター共有の前提が意味をなさない場合があります。これは、CNN への入力画像が何らかの特定の中心構造を持っている場合に特に当てはまります。そのため、異なる空間的位置ではまったく異なる特徴が学習されることが予想されます。実際の例の 1 つは、入力が画像の中央に配置された顔である場合です。画像のさまざまな部分で、目固有または髪固有のさまざまな特徴が学習されることが期待できます。その場合、パラメータ共有スキームを緩和し、代わりにその層を単に「ローカル接続層」と呼ぶのが一般的です。

プーリング層

ストライド 2 での 2x2 maxpooling の実際の例。

2x2 フィルターおよびストライド = 2 を使用した最大プーリング
CNN のもう 1 つの重要な概念は、非線形ダウンサンプリングの形式であるプーリングです。プーリングを実装する非線形関数はいくつかありますが、最大プーリングが最も一般的です。入力画像を一連の四角形に分割し、そのようなサブ領域ごとに最大値を出力します。

直感的には、フィーチャの正確な位置は、他のフィーチャと比較した大まかな位置ほど重要ではありません。これは、畳み込みニューラル ネットワークでのプーリングの使用の背後にある考え方です。プーリング層は、表現の空間サイズを段階的に縮小し、パラメータの数、メモリ フットプリント、ネットワーク内の計算量を削減し、それによってオーバーフィッティングを制御する役割も果たします。これはダウンサンプリングとして知られています。 CNN アーキテクチャでは、連続する畳み込み層 (通常、各層の後に ReLU 層などの活性化関数が続く) の間にプーリング層を定期的に挿入するのが一般的です。[72]: 460–461 プーリング層はローカルな翻訳の不変性に貢献しますが、グローバル プーリングの形式が使用されない限り、CNN でグローバルな翻訳の不変性を提供しません。[14][71]プーリング層は通常、入力のすべての深さまたはスライスで独立して動作し、空間的にサイズを変更します。最大プーリングの非常に一般的な形式は、サイズ 2×2 のフィルターを含むレイヤーで、ストライド 2 で適用されます。これにより、入力内のすべての深度スライスが幅と高さの両方に沿って 2 ずつサブサンプリングされ、アクティベーションの 75% が破棄されます。
f
×
、
Y
(
S
)
=
最大
ある
、
b
=
0
1
S
2
×
+
ある
、
2
Y
+
b
。
{\displaystyle f_{X,Y}(S)=\max _{a,b=0}^{1}S_{2X+a,2Y+b}.}この場合、すべての max 演算は 4 つの数値を超えます。深さの次元は変更されません (これは他の形式のプーリングにも当てはまります)。

プーリングユニットは最大プーリング以外にも、平均プーリングやℓ2ノルムプーリングなどの機能を使用できます。平均プーリングは歴史的によく使用されていましたが、実際には一般にパフォーマンスが優れている最大プーリングと比較して最近はあまり使われなくなっています。[74]

表現サイズの急速な空間縮小の影響により、[どちら?] より小さなフィルターを使用するか [75]、プーリング層を完全に破棄する傾向が最近あります。


RoI プーリングのサイズは 2x2。この例では、領域提案 (入力パラメーター) のサイズは 7x5 です。
「関心領域」プーリング (RoI プーリングとも呼ばれる) は最大プーリングの変形であり、出力サイズが固定され、入力四角形がパラメーターとなります。[要出典]

プーリングはダウンサンプリング手法であり、Fast R-CNN[77] アーキテクチャに基づく物体検出のための畳み込みニューラル ネットワークの重要なコンポーネントです。

チャネル最大プーリング
チャネル最大プーリング (CMP) 演算層は、冗長な情報を削除する目的で、連続する特徴マップの対応する位置の間でチャネル側に沿って MP 演算を実行します。 CMP を使用すると、重要な特徴がより少ないチャネル内に集まります。これは、より多くの識別特徴を必要とするきめの細かい画像分類にとって重要です。一方、CMP 操作のもう 1 つの利点は、最初の完全接続 (FC) 層に接続する前に、特徴マップのチャネル番号を小さくできることです。 MP 演算と同様に、CMP 層の入力特徴マップと出力特徴マップをそれぞれ F ∈ R(C×M×N) と C ∈ R(c×M×N) と表します。ここで、C と c は入力特徴マップと出力特徴マップのチャネル番号、M と N はそれぞれ特徴マップの幅と高さです。 CMP 操作では、機能マップのチャネル番号のみが変更されることに注意してください。 MP 操作とは異なり、特徴マップの幅と高さは変更されません。[78]

ReLU層
ReLU は、1969 年に福島邦彦によって導入された Rectified Linear Unit の略称です [35] [36]。 ReLUは非飽和活性化関数を適用します 
f
(
×
)
=
最大
(
0
、
×
)
{\textstyle f(x)=\max(0,x)}.[66]負の値をゼロに設定することで、アクティベーション マップから効果的に削除します。[79]これにより、畳み込み層の受容野に影響を与えることなく、決定関数とネットワーク全体に非線形性が導入されます。 2011 年に、Xavier Glorot、Antoine Bordes、Yoshua Bengio は、2011 年以前に広く使用されていた活性化関数と比較して、ReLU がより深いネットワークのトレーニングを可能にすることを発見しました[80]。

他の関数を使用して非線形性を高めることもできます。たとえば、飽和双曲線正接などです。 
f
(
×
)
=
タン
⁡
(
×
)
{\displaystyle f(x)=\tanh(x)}, 
f
(
×
)
=
|
タン
⁡
(
×
)
|
{\displaystyle f(x)=|\tanh(x)|}、およびシグモイド関数 
σ
(
×
)
=
(
1
+
e
−
×
)
−
1
{\textstyle \sigma (x)=(1+e^{-x})^{-1}}。 ReLU は一般化の精度に重大な影響を与えることなく、ニューラル ネットワークを数倍高速にトレーニングできるため、他の関数よりも好まれることがよくあります [81]。

全結合層
いくつかの畳み込み層と最大プーリング層の後、最終的な分類は完全に接続された層によって行われます。通常の (非畳み込み) 人工ニューラル ネットワークに見られるように、完全に接続された層のニューロンは、前の層のすべての活性化と接続しています。したがって、それらのアクティベーションは、行列乗算の後にバイアス オフセット (学習または固定バイアス項のベクトル加算) を行うアフィン変換として計算できます。

損失層
詳細は「損失関数」および「分類のための損失関数」を参照
「損失層」または「損失関数」は、ネットワークの予測出力と（教師あり学習中の）真のデータ ラベルとの間の偏差にトレーニングがどのようにペナルティを与えるかを指定します。特定のタスクに応じて、さまざまな損失関数を使用できます。

Softmax 損失関数は、K 個の相互に排他的なクラスのうちの 1 つのクラスを予測するために使用されます。[nb 3] シグモイド クロスエントロピー損失は、K 個の独立した確率値を予測するために使用されます。 
[
0
、
1
】
{\displaystyle [0,1]}。ユークリッド損失は実数値ラベルへの回帰に使用されます 
(
−
∞
、
∞
)
{\displaystyle (-\infty ,\infty )}。

ハイパーパラメータ

このセクションには検証のため追加の引用が必要です。このセクションに信頼できる情報源への引用を追加して、記事の改善にご協力ください。出典のない素材は異議を申し立てられ、削除される場合があります。 (2017 年 6 月) (このメッセージを削除する方法とタイミングについてはこちらをご覧ください)
ハイパーパラメータは、学習プロセスを制御するために使用されるさまざまな設定です。 CNN は、標準の多層パーセプトロン (MLP) よりも多くのハイパーパラメーターを使用します。

カーネルサイズ
カーネルは、一緒に処理されるピクセルの数です。通常、これはカーネルの寸法 (2x2 や 3x3 など) として表されます。

パディング
パディングとは、(通常は) 値 0 のピクセルを画像の境界に追加することです。これは、境界ピクセルが通常単一の受容野インスタンスのみに関与するため、境界ピクセルが出力から過小評価されない (失われる) ことを防ぐために行われます。適用されるパディングは通常、対応するカーネルの次元より 1 つ少ない値です。たとえば、3x3 カーネルを使用する畳み込み層は 2 ピクセルのパッド、つまり画像の両側に 1 ピクセルずつ割り当てられます。[要出典]

ストライド
ストライドは、解析ウィンドウが反復ごとに移動するピクセル数です。ストライド 2 は、各カーネルがその前のカーネルから 2 ピクセルだけオフセットされていることを意味します。

フィルターの数
特徴マップのサイズは深さとともに減少するため、入力層に近い層にはフィルターが少なくなる傾向がありますが、より高い層には多くのフィルターが含まれる可能性があります。各層での計算を均等化するために、特徴値 va とピクセル位置の積は層全体でほぼ一定に保たれます。入力に関するより多くの情報を保持するには、アクティベーションの総数 (特徴マップの数とピクセル位置の数を掛けたもの) を、あるレイヤーから次のレイヤーに減らさないように維持する必要があります。

特徴マップの数は容量を直接制御し、利用可能なサンプルの数とタスクの複雑さに依存します。

フィルターサイズ
文献に記載されている一般的なフィルター サイズは大きく異なり、通常はデータ セットに基づいて選択されます。一般的なフィルター サイズの範囲は 1x1 から 7x7 です。 2 つの有名な例として、AlexNet は 3x3、5x5、および 11x11 を使用しました。 Inceptionv3 では 1x1、3x3、および 5x5 が使用されました。

課題は、特定のデータセットを与えられた場合に、過剰適合せずに適切なスケールで抽象化を作成するために、適切な粒度レベルを見つけることです。

プールのタイプとサイズ
通常は最大プーリングが使用され、多くの場合 2x2 ディメンションが使用されます。これは、入力が大幅にダウンサンプリングされ、処理コストが削減されることを意味します。

プーリングを大きくすると信号の次元が小さくなり、許容できない情報損失が発生する可能性があります。多くの場合、重複しないプーリング ウィンドウが最高のパフォーマンスを発揮します。[74]

拡張
拡張には、カーネル内のピクセルを無視することが含まれます。これにより、大幅な信号損失を引き起こすことなく処理/メモリが削減される可能性があります。 3x3 カーネルで 2 の拡張を行うと、カーネルは 5x5 に拡張されますが、それでも 9 (等間隔) ピクセルが処理されます。したがって、4 を拡張すると、カーネルは 7x7 に拡張されます。[要出典]

翻訳の等価性とエイリアシング
一般に、CNN は入力のシフトに対して不変であると想定されています。 1 を超えるストライドを持たない CNN 内の畳み込み層またはプーリング層は、入力の変換と実際に等価です。[71]ただし、1 より大きいストライドを持つ層はナイキスト シャノンのサンプリング定理を無視し、入力信号のエイリアシングを引き起こす可能性があります[71]。原則として、CNN はアンチエイリアシング フィルターを実装できますが、実際にはこれが起こらず [82]、変換と等価ではないモデルが生成されることが観察されています。さらに、CNN が全結合層を利用する場合、全結合層は入力のシフトに対して不変ではないため、変換の等変性は変換の不変性を意味しません。[83][14]。完全な翻訳の不変性を実現する 1 つの解決策は、ネットワーク全体でダウンサンプリングを回避し、最終層でグローバル平均プーリングを適用することです。[71]さらに、ダウンサンプリング操作前のアンチエイリアシング[84]、空間変換ネットワーク[85]、データ拡張、プーリングと組み合わせたサブサンプリング[14]、カプセルニューラルネットワーク[86]など、他の部分的な解決策もいくつか提案されています。

評価
最終モデルの精度は、最初に別に設定されたデータセットのサブ部分 (テストセットと呼ばれることが多い) に基づいています。また、k 分割交差検証などの方法が適用される場合もあります。他の戦略には、等角予測の使用が含まれます。[87][88]

正則化方法
詳細は「正則化 (数学)」を参照

このセクションには検証のため追加の引用が必要です。このセクションに信頼できる情報源への引用を追加して、記事の改善にご協力ください。出典のない素材は異議を申し立てられ、削除される場合があります。 (2017 年 6 月) (このメッセージを削除する方法とタイミングについてはこちらをご覧ください)
正則化は、不適切な問題を解決したり、過剰適合を防止したりするために追加情報を導入するプロセスです。 CNN はさまざまなタイプの正則化を使用します。

経験的
ドロップアウト
完全に接続された層はパラメータの大部分を占めるため、オーバーフィッティングが発生する傾向があります。過学習を減らす方法の 1 つは、2014 年に導入されたドロップアウトです。[89]各トレーニング段階で、個々のノードは確率でネットから「ドロップアウト」（無視）されます。 
1
−
p
{\displaystyle 1-p} または確率で保持される 
p
{\displaystyle p} により、縮小されたネットワークが残ります。ドロップアウトされたノードへの着信エッジと発信エッジも削除されます。その段階では、縮小されたネットワークのみがデータでトレーニングされます。削除されたノードは、元の重みでネットワークに再挿入されます。

トレーニング段階では、 
p
{\displaystyle p} は通常 0.5 です。入力ノードの場合、入力ノードが無視されると情報が直接失われるため、通常はこれよりもはるかに高くなります。

トレーニング終了後のテスト時には、理想的には、可能なすべてのサンプルの平均を見つけたいと考えています。 
2
n
{\displaystyle 2^{n}} 個のドロップアウト ネットワーク。残念ながら、これは大きな値では実現できません。 
n
{\displaystyle n}。ただし、各ノードの出力を係数で重み付けした完全なネットワークを使用することで、近似値を見つけることができます。 
p
{\displaystyle p} なので、どのノードの出力の期待値もトレーニング段階と同じになります。これがドロップアウト法の最大の貢献です。 
2
n
{\displaystyle 2^{n}} ニューラル ネットワークを使用するため、モデルの組み合わせが可能になるため、テスト時には 1 つのネットワークのみをテストする必要があります。

すべてのトレーニング データですべてのノードをトレーニングすることを回避することで、ドロップアウトによる過学習が減少します。この方法により、トレーニング速度も大幅に向上します。これにより、ディープ ニューラル ネットワークでもモデルの組み合わせが実用的になります。この技術はノードの相互作用を減らし、新しいデータによりよく一般化する、より堅牢な特徴[要説明]を学習させるようです。

ドロップコネクト
DropConnect は、各出力ユニットではなく各接続を確率でドロップできるドロップアウトの一般化です。 
1
−
p
{\displaystyle 1-p}。したがって、各ユニットは前の層のユニットのランダムなサブセットから入力を受け取ります。 [90]

DropConnect は、モデル内に動的スパース性を導入するという点でドロップアウトに似ていますが、スパース性が層の出力ベクトルではなく重みにあるという点で異なります。言い換えれば、DropConnect による完全接続層は、トレーニング段階で接続がランダムに選択される疎接続層になります。

確率的プーリング
Dropout の主な欠点は、ニューロンが完全に接続されていない畳み込み層では同じ利点が得られないことです。

Dropout の前でさえ、2013 年には確率的プーリングと呼ばれる手法 [91] が導入され、従来の決定論的プーリング操作は確率的手順に置き換えられました。この手順では、各プーリング領域内のアクティベーションが、プーリング領域内のアクティビティによって与えられる多項分布に従ってランダムに選択されます。このアプローチにはハイパーパラメーターがなく、ドロップアウトやデータ拡張などの他の正則化アプローチと組み合わせることができます。

確率的プーリングの別の見方は、標準の最大プーリングと同等ですが、入力イメージの多数のコピーがあり、それぞれが小さな局所的な変形を持っているというものです。これは入力画像の明示的な弾性変形に似ており[92]、MNIST データセットで優れたパフォーマンスを実現します。[92]多層モデルで確率的プーリングを使用すると、上位層の選択が下位層の選択から独立しているため、指数関数的な数の変形が得られます。

人工データ
詳細は「データ拡張」を参照
モデルの過学習の程度はその能力と受け取るトレーニング量の両方によって決まるため、畳み込みネットワークにより多くのトレーニング例を提供すると、過学習を減らすことができます。多くの場合、トレーニングに使用できる十分なデータがないため、特に一部の部分を後のテストのために保存する必要があることを考慮すると、(可能であれば) 新しいデータを最初から生成するか、既存のデータを撹乱して新しいデータを作成する 2 つのアプローチがあります。後者は 1990 年代半ばから使用されています [49]。たとえば、入力画像をトリミング、回転、または再スケールして、元のトレーニング セットと同じラベルを持つ新しいサンプルを作成できます。[93]

明示的な
早期停止
詳細は「早期停止」を参照
ネットワークの過学習を防ぐ最も簡単な方法の 1 つは、過学習が発生する前にトレーニングを停止することです。学習プロセスが停止してしまうという欠点があります。

パラメータの数
過学習を防ぐもう 1 つの簡単な方法は、パラメーターの数を制限することです。通常は、各層の隠れユニットの数を制限するか、ネットワークの深さを制限します。畳み込みネットワークの場合、フィルター サイズはパラメーターの数にも影響します。パラメーターの数を制限すると、ネットワークの予測能力が直接制限され、データに対して実行できる関数の複雑さが軽減され、過剰適合の量が制限されます。これは「ゼロノルム」に相当します。

体重の減少
追加される正則化の単純な形式は重み減衰です。これは、重みの合計 (L1 ノルム) または重みベクトルの 2 乗の大きさ (L2 ノルム) に比例する追加の誤差を各ノードの誤差に単純に追加します。許容可能なモデルの複雑さのレベルは、比例定数 ('alpha' ハイパーパラメーター) を増やすことで減らすことができ、その結果、大きな重みベクトルに対するペナルティが増加します。

L2 正則化は、正則化の最も一般的な形式です。これは、目的内のすべてのパラメータの 2 乗の大きさに直接ペナルティを課すことで実装できます。 L2 正則化では、ピーキーな重みベクトルに大きなペナルティを与え、拡散した重みベクトルを優先するという直観的な解釈が行われます。重みと入力間の乗算相互作用により、これには、ネットワークが一部の入力を多く使用するのではなく、すべての入力を少しだけ使用するよう促すという有益な特性があります。

L1 正則化も一般的です。最適化中に重みベクトルがスパースになります。言い換えれば、L1 正則化を備えたニューロンは、最終的に最も重要な入力のまばらなサブセットのみを使用することになり、ノイズの多い入力に対してほぼ不変になります。 L1 正則化と L2 正則化を組み合わせることができます。これは弾性ネット正則化と呼ばれます。

最大ノルム制約
正則化の別の形式は、すべてのニューロンの重みベクトルの大きさに絶対的な上限を強制し、投影勾配降下法を使用して制約を強制することです。実際には、これは通常どおりパラメータ更新を実行し、その後重みベクトルをクランプすることで制約を強制することに相当します。 
w
→{\displaystyle {\vec {w}}}を満たすすべてのニューロン 
‖
w
→
‖
2
<
c
{\displaystyle \|{\vec {w}}\|_{2}<c}。の典型的な値 
c
{\displaystyle c} は 3 ～ 4 の順序です。一部の論文では、この形式の正則化を使用した場合の改善が報告されています[94]。

階層型座標フレーム
プーリングでは、高レベルのパーツ (顔画像の鼻と口など) 間の正確な空間関係が失われます。これらの関係はアイデンティティ認識に必要です。各フィーチャが複数のプールで発生するようにプールをオーバーラップすると、情報の保持に役立ちます。翻訳だけでは、幾何学的関係の理解を、異なる方向やスケールなど、根本的に新しい視点に推定することはできません。その一方で、人々は外挿するのが非常に得意です。新しい形を見た後は、別の視点からそれを認識できるようになります。 [95]

この問題に対処する初期の一般的な方法は、ネットワークがこれらの変動に対処できるように、さまざまな方向、スケール、照明などで変換されたデータでネットワークをトレーニングすることです。これは、大規模なデータセットの場合、計算負荷が高くなります。別の方法は、座標フレームの階層を使用し、ニューロンのグループを使用して、特徴の形状と網膜に対する姿勢の結合を表すことです。網膜に対する姿勢は、網膜の座標フレームと固有の特徴の座標フレームの間の関係です。

したがって、何かを表現する 1 つの方法は、その中に座標フレームを埋め込むことです。これにより、大きな特徴を、その部分の姿勢の一貫性を利用して認識することができます (たとえば、鼻と口の姿勢は、顔全体の姿勢の一貫した予測を可能にします)。このアプローチにより、下位レベルのエンティティ (例: 鼻や口) がポーズの予測に同意したときに、上位レベルのエンティティ (例: 顔) が存在することが保証されます。ポーズを表すニューロン活動のベクトル (「ポーズ ベクトル」) により、線形操作としてモデル化された空間変換が可能になり、ネットワークが視覚エンティティの階層を学習し、複数の視点にわたって一般化することが容易になります。これは、人間の視覚システムが形状を表現するために座標フレームを課す方法と似ています。[97]

アプリケーション
画像認識
CNN は画像認識システムでよく使用されます。 2012 年には、MNIST データベースのエラー率が 0.23% であると報告されました [26]。画像分類に CNN を使用することに関する別の論文では、学習プロセスが「驚くほど高速」だったと報告しています。同論文では、2011 年の時点で公表されている最良の結果は、MNIST データベースと NORB データベースで達成されたとしています。[23]その後、AlexNet[98] と呼ばれる同様の CNN が ImageNet Large Scale Visual Recognition Challenge 2012 で優勝しました。

CNN を顔認識に適用すると、エラー率が大幅に減少しました。[99]別の論文では、「10 人以上の被写体の 5,600 枚の静止画像」の認識率が 97.6% であると報告しています。 CNN は、手動トレーニング後に客観的な方法でビデオ品質を評価するために使用されました。結果として得られたシステムの二乗平均平方根誤差は非常に低くなりました。[100]

ImageNet 大規模視覚認識チャレンジは、数百万の画像と数百のオブジェクト クラスを使用したオブジェクトの分類と検出のベンチマークです。大規模な視覚認識チャレンジである ILSVRC 2014 [101] では、ほぼすべての上位チームが基本フレームワークとして CNN を使用しました。優勝した GoogLeNet[102] (DeepDream の基盤) は、オブジェクト検出の平均精度を 0.439329 に向上させ、分類誤差を 0.06656 に減少させ、これまでで最高の結果となりました。そのネットワークには 30 以上のレイヤーが適用されています。 ImageNet テストにおける畳み込みニューラル ネットワークのパフォーマンスは人間のパフォーマンスに近かった[103]。最良のアルゴリズムでも、花の茎にいる小さなアリや羽ペンを手に持っている人など、小さいか薄いオブジェクトには依然として苦戦しています。また、フィルターで歪んだ画像にも問題があり、これは現代のデジタル カメラでますます一般的な現象です。対照的に、そのような種類の画像が人間を悩ませることはほとんどありません。しかし、人間は他の問題で困難を抱える傾向があります。たとえば、畳み込みニューラル ネットワークはこれを処理しますが、オブジェクトを特定の種類の犬や鳥の種類などの細かいカテゴリに分類するのは苦手です。[要出典]

2015 年、多層 CNN は、部分的に遮られている場合でも、逆さまを含む幅広い角度から顔を検出し、競争力のあるパフォーマンスを発揮できることを実証しました。このネットワークは、さまざまな角度や向きの顔を含む 200,000 枚の画像と、顔のないさらに 2,000 万枚の画像のデータベースでトレーニングされました。彼らは 50,000 回の反復にわたって 128 枚の画像のバッチを使用しました。[104]

ビデオ分析
画像データ ドメインと比較すると、CNN をビデオ分類に適用する作業は比較的少ないです。ビデオには別の (時間的) 次元があるため、画像よりも複雑です。ただし、ビデオ ドメインへの CNN の拡張がいくつか検討されています。 1 つのアプローチは、空間と時間を入力の等価次元として扱い、時間と空間の両方で畳み込みを実行することです。[105][106]もう 1 つの方法は、空間ストリーム用と時間ストリーム用の 2 つの畳み込みニューラル ネットワークの機能を融合することです。[107][108][109]長短期記憶 (LSTM) リカレント ユニットは通常、フレーム間またはクリップ間の依存関係を考慮して CNN の後に組み込まれます。[110][111]畳み込みゲート制限ボルツマン マシン [112] と独立部分空間分析 [113] に基づいて、時空間特徴をトレーニングするための教師なし学習スキームが導入されました。その応用例はテキストからビデオへのモデルで見ることができます。[要出典]

自然言語処理
CNN は自然言語処理についても研究されています。 CNN モデルはさまざまな NLP 問題に効果的であり、意味解析、[114] 検索クエリの取得、[115] 文モデリング、[116] 分類、[117] 予測 [118]、その他の従来の NLP タスクで優れた結果を達成しました。[119]リカレント ニューラル ネットワークなどの従来の言語処理手法と比較すると、CNN は系列シーケンスの仮定に依存しない言語のさまざまな文脈上の現実を表現できますが、古典的な時系列モデリングが必要な場合には RNN の方が適しています。[120][121][122][123]

異常検知
1 次元畳み込みを含む CNN は、時間領域の異常を検出するために、教師なしモデルによって周波数領域 (スペクトル残差) の時系列で使用されました。

創薬
CNN は創薬に使用されています。分子と生物学的タンパク質の間の相互作用を予測することで、潜在的な治療法を特定できます。 2015 年、Atomwise は、構造ベースの医薬品設計のための初の深層学習ニューラル ネットワークである AtomNet を導入しました。[125]このシステムは、化学相互作用の 3 次元表現に基づいて直接トレーニングします。画像認識ネットワークが、より小さく空間的に近接した特徴をより大きな複雑な構造に合成する方法を学習するのと同様に、AtomNet は芳香族性、sp3 炭素、水素結合などの化学的特徴を発見します。その後、AtomNet は、複数の疾患標的、特にエボラウイルス [127] と多発性硬化症の治療法に対する新規の候補生体分子を予測するために使用されました [128]。

チェッカーゲーム
CNN はチェッカー ゲームで使用されています。 1999 年から 2001 年にかけて、Fogel と Chellapilla は、畳み込みニューラル ネットワークが共進化を使用してチェッカーをプレイする方法を学習する方法を示す論文を発表しました。この学習プロセスでは、以前の人間のプロのゲームは使用されず、チェッカーボードに含まれる最小限の情報セット、つまり駒の位置と種類、および両側の駒の数の差に焦点が当てられました。最終的に、プログラム (Blondie24) はプレイヤーとの 165 試合でテストされ、最高の 0.4% にランクされました [129] [130]。また、「エキスパート」レベルのプレーでプログラム Chinook に対して勝利を収めた[131]。

行く
CNN はコンピューター囲碁で使用されています。 2014 年 12 月、Clark と Storkey は、人間のプロのゲームのデータベースからの教師あり学習によって訓練された CNN が GNU Go を上回るパフォーマンスを示し、Fuego のプレイにかかった時間のほんの一部でモンテカルロ木探索 Fuego 1.1 に対していくつかのゲームに勝つことができることを示す論文を発表しました。 [132]その後、大規模な 12 層の畳み込みニューラル ネットワークが 55% の局面でプロの手を正確に予測し、これは人間の 6 段プレーヤーの精度と同等であることが発表されました。訓練された畳み込みネットワークを直接使用して、検索を行わずに囲碁のゲームをプレイすると、従来の検索プログラム GNU Go を 97% のゲームで上回り、手ごとに 1 万のプレイアウト (約 100 万の局面) をシミュレートするモンテカルロ木検索プログラム Fuego のパフォーマンスに匹敵しました [133]。

MCTS を推進するための手を選択する (「ポリシー ネットワーク」) および局面を評価する (「バリュー ネットワーク」) ためのいくつかの CNN は、当時最高の人間のプレイヤーに初めて勝った AlphaGo によって使用されました。 [134]

時系列予測
一般に、リカレント ニューラル ネットワークは、時系列予測 (およびシーケンス モデリング全般) に最適なニューラル ネットワーク アーキテクチャであると考えられていますが、最近の研究では、畳み込みネットワークが同等かそれ以上のパフォーマンスを発揮できることが示されています。[135][11]拡張畳み込み [136] により、1 次元畳み込みニューラル ネットワークが時系列の依存関係を効果的に学習できるようになる可能性があります。 [137]畳み込みは RNN ベースのソリューションよりも効率的に実装でき、勾配の消失 (または爆発) の影響を受けません。[138]畳み込みネットワークは、学習対象となる類似の時系列が複数ある場合に、予測パフォーマンスを向上させることができます。[139] CNN は、時系列分析のさらなるタスク (時系列分類 [140] や分位予測 [141] など) にも適用できます。

文化遺産と3Dデータセット
楔形文字が書かれた粘土板などの考古学的発見物が 3D スキャナーを使用して取得されることが増えているため、GigaMesh ソフトウェア フレームワークで作成されたほぼ 2000 の正規化された 2-D および 3-D データセットを提供する HeiCuBeDa [142] を含むベンチマーク データセットが利用可能になってきています。したがって、曲率ベースの測定は、幾何学的ニューラル ネットワーク (GNN) と組み合わせて使用​​されます。これらの粘土板の時代分類は人類史上最古の文書の一つであるためである[144][145]。

微調整
多くのアプリケーションでは、トレーニング データはあまり入手できません。畳み込みニューラル ネットワークでは通常、過学習を避けるために大量のトレーニング データが必要です。一般的な手法は、関連ドメインからの大規模なデータ セットでネットワークをトレーニングすることです。ネットワーク パラメーターが収束すると、ドメイン内データを使用して追加のトレーニング ステップが実行され、ネットワークの重みが微調整されます。これは転移学習として知られています。さらに、この手法により、畳み込みネットワーク アーキテクチャを小さなトレーニング セットの問題にうまく適用できるようになります。 [146]

人間が解釈できる説明
コンピュータ ビジョンでは、エンドツーエンドのトレーニングと予測が一般的に行われています。ただし、自動運転車などの重要なシステムには、人間が解釈できる説明が必要です。[147]視覚的顕著性、空間的注意、時間的注意の最近の進歩により、最も重要な空間領域/時間的瞬間を視覚化して CNN 予測を正当化できる可能性があります。[148][149]

関連するアーキテクチャ
ディープ Q ネットワーク
ディープ Q ネットワーク (DQN) は、ディープ ニューラル ネットワークと強化学習の一種である Q ラーニングを組み合わせた深層学習モデルの一種です。以前の強化学習エージェントとは異なり、CNN を利用する DQN は、強化学習を通じて高次元の感覚入力から直接学習できます。[150]

暫定結果は 2014 年に発表され、2015 年 2 月に関連論文が発表されました。 [151]この研究では、Atari 2600 ゲームへの応用について説明しました。他の深層強化学習モデルがこれに先立って登場しました。[152]

深い信念ネットワーク
詳細は「深い信念のネットワーク」を参照
畳み込み深層信念ネットワーク (CDBN) は、畳み込みニューラル ネットワークと非常によく似た構造を持ち、深層信念ネットワークと同様にトレーニングされます。したがって、CNN と同様に画像の 2D 構造を利用し、深い信念ネットワークのような事前トレーニングを利用します。これらは、多くの画像および信号処理タスクで使用できる汎用構造を提供します。 CIFAR[153] のような標準画像データセットのベンチマーク結果は、CDBN を使用して取得されています。[154]

