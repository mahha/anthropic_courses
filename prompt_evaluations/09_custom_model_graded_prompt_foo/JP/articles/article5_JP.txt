手書き認識 (HWR) は、手書きテキスト認識 (HTR) とも呼ばれ、紙の文書、写真、タッチ スクリーン、その他のデバイスなどのソースからのわかりやすい手書き入力を受信して​​解釈するコンピューターの機能です。[1][2]。書かれたテキストの画像は、光学スキャン (光学文字認識) またはインテリジェント単語認識によって紙から「オフライン」で検出できます。あるいは、ペン先の動きは、例えばペンベースのコンピュータ画面表面によって「オンライン」で感知されてもよいが、利用可能な手がかりがより多くあるため、一般にこの作業はより容易である。手書き認識システムは書式設定を処理し、文字への正確な分割を実行し、最も可能性のある単語を検索します。

オフライン認識
オフライン手書き認識には、画像内のテキストを、コンピューターやテキスト処理アプリケーションで使用できる文字コードに自動的に変換することが含まれます。このフォームによって取得されたデータは、手書きの静的表現とみなされます。人によって手書きスタイルが異なるため、オフラインでの手書き認識は比較的困難です。そして、現時点では、OCR エンジンは主に機械で印刷されたテキストと、手で「印刷された」(大文字で書かれた) テキストの ICR に重点を置いています。

伝統の技
文字抽出
オフライン文字認識では、多くの場合、フォームまたはドキュメントのスキャンが必要になります。これは、スキャンされた画像に含まれる個々の文字を抽出する必要があることを意味します。このステップを実行できるツールが存在します。[3]ただし、このステップにはよくある不完全な点がいくつかあります。最も一般的なのは、接続された文字が両方の文字を含む単一のサブイメージとして返される場合です。これは認識段階で大きな問題を引き起こします。それでも、文字が接続されるリスクを軽減するアルゴリズムが多数利用可能です。

文字認識
個々の文字が抽出された後、認識エンジンを使用して、対応するコンピュータ文字が識別されます。現在、いくつかの異なる認識技術が利用可能です。

特徴抽出
特徴抽出は、ニューラル ネットワーク認識装置と同様の方法で機能します。ただし、プログラマは重要だと思われるプロパティを手動で決定する必要があります。このアプローチにより、認識エンジンは識別に使用されるプロパティをより詳細に制御できるようになります。ただし、このアプローチを使用するシステムは、プロパティが自動的に学習されないため、ニューラル ネットワークよりも大幅に多くの開発時間を必要とします。

現代の技術
従来の技術は認識のために個々の文字をセグメント化することに重点を置いていますが、最新の技術はセグメント化されたテキスト行内のすべての文字を認識することに重点を置いています。特に、以前に使用されていた制限的な特徴エンジニアリングを回避し、視覚的な特徴を学習できる機械学習技術に焦点を当てています。最先端の方法では、畳み込みネットワークを使用して、テキスト行画像のいくつかの重なり合うウィンドウにわたって視覚的特徴を抽出し、リカレント ニューラル ネットワークが文字の確率を生成するために使用します。[4]

オンライン認識
オンライン手書き認識には、特別なデジタイザーまたは PDA に書かれたテキストの自動変換が含まれ、センサーがペン先の動きとペンアップ/ペンダウンの切り替えを検出します。この種のデータはデジタル インクとして知られており、手書きのデジタル表現とみなすことができます。取得された信号は、コンピューターやテキスト処理アプリケーション内で使用できる文字コードに変換されます。

オンライン手書き認識インターフェイスの要素には通常、次のものが含まれます。

ユーザーが書くためのペンまたはスタイラス
出力ディスプレイと一体化されるか、出力ディスプレイに隣接するタッチ感知面。
筆記面上のスタイラスの動きを解釈し、結果として得られるストロークをデジタル テキストに変換するソフトウェア アプリケーション。
オンライン手書き認識のプロセスは、いくつかの一般的な手順に分類できます。

前処理、
特徴抽出と
分類
前処理の目的は、認識に悪影響を与える可能性のある入力データ内の無関係な情報を破棄することです。[5]これは速度と精度に関係します。前処理は通常、二値化、正規化、サンプリング、平滑化、ノイズ除去で構成されます[6]。 2 番目のステップは特徴抽出です。前処理アルゴリズムから受け取った 2 次元以上のベクトル場から高次元データが抽出されます。このステップの目的は、認識モデルにとって重要な情報を強調することです。このデータには、筆圧、速度、書き込み方向の変化などの情報が含まれる場合があります。最後の大きなステップは分類です。このステップでは、さまざまなモデルを使用して、抽出された特徴をさまざまなクラスにマッピングし、その特徴が表す文字または単語を識別します。

ハードウェア
キーボード入力の代わりに手書き認識を組み込んだ商用製品が 1980 年代初頭に導入されました。例としては、Pencept Penpad [7] や Inforite POS 端末などの手書き端末が挙げられます [8]。パーソナル コンピュータの大規模な消費者市場の出現に伴い、パーソナル コンピュータのキーボードとマウスを単一のポインティング/手書きシステムに置き換えるために、Pencept や CIC [10] などの製品がいくつか導入されました。最初に市販されたタブレット型ポータブル コンピュータは、1989 年 9 月に発売された GRiD Systems の GRiDPad でした。そのオペレーティング システムは MS-DOS に基づいていました。

1990 年代初頭、NCR、IBM、EO などのハードウェア メーカーは、GO Corp. が開発した PenPoint オペレーティング システムを実行するタブレット コンピュータを発売しました。PenPoint は手書き認識とジェスチャを全面的に使用し、その機能をサードパーティ ソフトウェアに提供しました。 IBM のタブレット コンピューターは、ThinkPad の名前を初めて使用し、IBM の手書き認識を使用しました。この認識システムは後に Microsoft Windows for Pen Computing と IBM の Pen for OS/2 に移植されました。これらはどれも商業的に成功しませんでした。

エレクトロニクスの進歩により、手書き認識に必要な計算能力がタブレット コンピューターよりも小さなフォーム ファクターに収まるようになり、手書き認識は携帯型 PDA の入力方法としてよく使用されます。書面による入力を提供する最初の PDA は Apple Newton で、これにより、合理化されたユーザー インターフェイスの利点が一般に公開されました。しかし、ユーザーの筆記パターンを学習しようとするソフトウェアの信頼性が低かったため、このデバイスは商業的には成功しませんでした。 Newton OS 2.0 のリリースまでに、モードレス誤り訂正など現在の認識システムにはまだ見られない独自の機能を含め、手書き認識が大幅に改善されましたが、主に否定的な第一印象が作られていました。 Apple Newton の廃止後、この機能は Mac OS X 10.2 以降に Inkwell として組み込まれました。

Palm はその後、Graffiti 認識システムに基づいた一連の PDA を発売し、成功を収めました。 Graffiti は、文字ごとに一連の「ユニストローク」、つまり 1 ストロークのフォームを定義することにより、使いやすさを向上させました。これにより、誤入力の可能性は狭まりましたが、ストローク パターンの記憶によりユーザーの学習曲線は長くなりました。 Graffiti 手書き認識はゼロックスが保有する特許を侵害していることが判明し、Palm は Graffiti を CIC 手書き認識のライセンス版に置き換えました。CIC 手書き認識は、一筆書き形式もサポートしていますが、ゼロックス特許よりも古いものでした。侵害に関する裁判所の認定は上訴で取り消され、その後の上訴で再び覆されました。その後、関係当事者はこの特許および他の特許に関する和解交渉を行った。

タブレット PC は、デジタイザ タブレットとスタイラスを備えたノートブック コンピュータで、ユーザーはユニットの画面にテキストを手書きできます。オペレーティング システムは手書きを認識し、テキストに変換します。 Windows Vista および Windows 7 には、英語、日本語、繁体字中国語、簡体字中国語、韓国語のユーザーの書き方パターンや語彙を学習する個人用設定機能が含まれています。この機能には、ユーザーの手書きのサンプルを要求し、それを使用してシステムを再トレーニングしてより高精度の認識を実現する「パーソナライゼーション ウィザード」が含まれます。このシステムは、PDA 用の Windows Mobile OS で採用されているそれほど高度ではない手書き認識システムとは異なります。

手書き認識は人々が慣れ親しんだ入力形式ですが、デスクトップ コンピュータでもラップトップでも広く使用されるには至っていません。キーボード入力のほうが速くて信頼性が高いというのは、今でも一般的に受け入れられています。 2006 年の時点では、多くの PDA が手書き入力を提供しており、場合によっては自然な筆記体手書きも受け入れられますが、精度には依然として問題があり、単純なオンスクリーン キーボードの方が効率的だと考える人もいます。

ソフトウェア
初期のソフトウェアは、文字が分離されている印刷物の手書きを理解できました。しかし、文字がつながった筆記体は、文字の分割に関わる問題であるセイヤーのパラドックスを引き起こしました。 1962 年に、当時モスクワにいたシェリア グベルマンは、最初の応用パターン認識プログラムを作成しました。[11]商用例は、Communications Intelligence Corporation や IBM などの企業から提供されています。

1990 年代初頭、ParaGraph International と Lexicus の 2 社が、筆記体の手書き認識を理解できるシステムを開発しました。 ParaGraph はロシアに拠点を置き、コンピューター科学者の Stepan Pachikov によって設立され、一方 Lexicus はスタンフォード大学の学生である Ronjon Nag と Chris Kortge によって設立されました。 ParaGraph CalliGrapher システムは Apple Newton システムに導入され、Lexicus Longhand システムは PenPoint および Windows オペレーティング システム用に市販されました。 Lexicus は 1993 年に Motorola に買収され、その後 Motorola 向けに中国語手書き認識および予測テキスト システムの開発を続けました。 ParaGraph は 1997 年に SGI に買収され、その手書き認識チームは P&I 部門を設立し、後に Vadem が SGI から買収しました。 Microsoft は、P&I が開発した CalliGrapher 手書き認識およびその他のデジタル インク テクノロジを 1999 年に Vadem から買収しました。

Wolfram Mathematica（8.0以降）は手書きまたはテキスト認識関数TextRecognizeも提供します。

研究

Sargur Srihari と Jonathan Hull によって開発された最初の手書き住所解釈システムでコンテキスト情報を活用するために使用された方法 [12]
手書き認識には、それを研究する学者の活発なコミュニティがあります。手書き認識に関する最大の会議は、偶数年に開催される手書き認識フロンティア国際会議 (ICFHR) と奇数年に開催される文書分析認識国際会議 (ICDAR) です。これらのカンファレンスはどちらも IEEE と IAPR によって承認されています。 2021 年に、ICDAR 議事録は LNCS と Springer によって出版される予定です。

活発な研究分野には次のようなものがあります。

オンライン認識
オフライン認識
署名の検証
郵便番号の解釈
銀行小切手の処理
ライターの認識
2009年以降の実績
2009 年以来、スイス AI ラボ IDSIA のユルゲン・シュミットフーバーの研究グループで開発されたリカレント ニューラル ネットワークとディープ フィードフォワード ニューラル ネットワークは、いくつかの国際手書きコンテストで優勝しています [13]。特に、Alex Graves らの双方向かつ多次元の長短期記憶 (LSTM) [14][15] は、学習する 3 つの異なる言語 (フランス語、アラビア語、ペルシア語) についての事前知識なしで、2009 年文書分析認識国際会議 (ICDAR) の接続された手書き認識のコンテストで 3 つのコンテストで優勝しました。 IDSIA の Dan Ciresan 氏らによるフィードフォワード ネットワーク向けの最近の GPU ベースの深層学習手法は、ICDAR 2011 オフライン中国語手書き認識コンテストで優勝しました。彼らのニューラル ネットワークは、Yann LeCun とニューヨーク大学の同僚による有名な MNIST 手書き数字問題 [17] において、人間と競合するパフォーマンス [16] を達成した最初の人工パターン認識装置でもありました。

ウォリック大学のベンジャミン グラハムは、（2017 年までに）「スパース畳み込みニューラル ネットワーク」に進化した畳み込みニューラル ネットワークへのアプローチを使用することで、2013 年の中国語手書き認識コンテストでわずか 2.61% のエラー率で優勝しました。[18][19]。