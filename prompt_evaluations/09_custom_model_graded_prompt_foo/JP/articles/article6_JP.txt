グラフィックス プロセッシング ユニット (GPU) は、当初はデジタル画像処理とコンピュータ グラフィックスの高速化を目的として設計された特殊な電子回路で、ディスクリート ビデオ カードとして存在するか、マザーボード、携帯電話、パーソナル コンピュータ、ワークステーション、ゲーム コンソールに組み込まれています。初期設計の後、GPU はその並列構造により、厄介な並列問題を伴う非グラフィック計算に役立つことが判明しました。その他の非グラフィカルな用途には、ニューラル ネットワークのトレーニングや暗号通貨マイニングが含まれます。

歴史
参照: ビデオ ディスプレイ コントローラー、ビデオ ハードウェア別のホーム コンピューターのリスト、およびスプライト (コンピューター グラフィックス)
1970年代
アーケード システム ボードは、1970 年代以来、特殊なグラフィック回路を使用してきました。初期のビデオ ゲーム ハードウェアでは、フレーム バッファー用の RAM が高価だったので、ディスプレイがモニター上でスキャンされる際に、ビデオ チップがデータを合成していました。[1]

特殊なバレル シフター回路は、CPU がガン ファイト (1975 年)、シー ウルフ (1976 年)、スペース インベーダー (1978 年) など、ミッドウェイとタイトーのさまざまな 1970 年代のアーケード ビデオ ゲームのフレームバッファ グラフィックスをアニメーション化するのに役立ちました。[2] 1979 年のナムコ ギャラクシアン アーケード システムでは、RGB カラー、マルチカラー スプライト、タイルマップの背景をサポートする特殊なグラフィック ハードウェアが使用されていました。ギャラクシアン ハードウェアは、アーケード ビデオ ゲームの黄金時代に、ナムコ、センチュリ、グレムリン、アイレム、コナミ、ミッドウェイ、ニチブツ、セガ、タイトーなどのゲーム会社によって広く使用されました [4]。


Atari 130XE マザーボード上の Atari ANTIC マイクロプロセッサ
1977 年の Atari 2600 では、Television Interface Adaptor と呼ばれるビデオ シフターが使用されていました [5]。 Atari 8 ビット コンピュータ (1979 年) には、「ディスプレイ リスト」を記述する命令を解釈するビデオ プロセッサである ANTIC が搭載されていました。これは、スキャン ラインが特定のビットマップ モードまたはキャラクタ モードにマッピングされる方法と、メモリの保存場所 (そのため、連続したフレーム バッファが必要ありませんでした) を記述します。[説明が必要][6] 6502 のマシン コード サブルーチンは、ディスプレイ リスト命令にビットを設定することでスキャン ライン上でトリガーできます。[説明が必要][7] ANTIC は、CPU に依存しないスムーズな垂直および水平スクロールもサポートしました。[8]

1980年代

NEC μPD7220A
NEC μPD7220 は、パーソナル コンピュータ グラフィックス ディスプレイ プロセッサを単一の大規模集積回路 (LSI) 集積回路チップとして初めて実装したものです。これにより、Number Nine Visual Technology のような低コストで高性能のビデオ グラフィックス カードの設計が可能になりました。 1980 年代半ばまでは最も有名な GPU となりました [9]。これは、PC 用の初の完全統合 VLSI (超大規模集積) 金属酸化膜半導体 (NMOS) グラフィックス ディスプレイ プロセッサであり、最大 1024 × 1024 の解像度をサポートし、新興 PC グラフィックス市場の基礎を築きました。これは多くのグラフィックス カードで使用され、Intel の最初のグラフィックス プロセッシング ユニットである Intel 82720 などのクローン用にライセンス供与されました [10]。 Williams Electronics のアーケード ゲーム Robotron 2084、Joust、Sinistar、Bubbles はすべて 1982 年にリリースされ、16 色の​​ビットマップで動作するためのカスタム ブリッター チップが含まれています。[11][12]。

1984 年、日立はパーソナル コンピュータ用初の主要な CMOS グラフィックス プロセッサである ARTC HD63484 を発売しました。 ARTC は、モノクロ モードの場合、最大 4K 解像度で表示できます。 1980 年代後半に多くのグラフィックス カードや端末で使用されました [13]。 1985 年に、ビットマップ操作、線描画、領域塗りつぶし用のブリッターを含むカスタム グラフィックス チップを搭載した Amiga がリリースされました。また、ビデオ ビームと同期してグラフィックス ハードウェア レジスタを操作したり (スキャンラインごとのパレット スイッチ、スプライトの多重化、ハードウェア ウィンドウ処理など)、またはブリッターを駆動したりできる、独自の単純な命令セットを備えたコプロセッサも含まれていました。 1986 年、テキサス インスツルメンツは、最初の完全にプログラム可能なグラフィックス プロセッサである TMS34010 をリリースしました。[14]汎用コードを実行できますが、グラフィックス指向の命令セットを持っていました。 1990 年から 1992 年にかけて、このチップは Texas Instruments Graphics Architecture (「TIGA」) Windows アクセラレータ カードの基礎となりました。


IBM 8514 マイクロ チャネル アダプター (メモリ アドオン付き)
1987 年に、IBM 8514 グラフィックス システムがリリースされました。これは、電子ハードウェアに固定機能 2D プリミティブを実装した、IBM PC 互換機用の最初のビデオ カードの 1 つです。 1987 年にリリースされたシャープの X68000 は、65,536 色のカラー パレットと、スプライト、スクロール、および複数のプレイフィールドのハードウェア サポートを備えたカスタム グラフィックス チップセット [15] を使用しました。カプコンのCPシステムアーケード基板の開発機として活躍した。 1989 年にリリースされた富士通の FM Towns コンピュータは、16,777,216 色の​​カラー パレットをサポートしていました [17]。 1988 年、ナムコ システム 21 [18] とタイトー エア システム [19] により、最初の専用ポリゴン 3D グラフィックス ボードがアーケードに導入されました。


IBM PS/55のマザーボード上のVGAセクション
IBM は 1987 年に、最大解像度 640 × 480 ピクセルの独自のビデオ グラフィックス アレイ (VGA) ディスプレイ規格を導入しました。 1988 年 11 月、NEC ホーム エレクトロニクスは、VGA の後継としてスーパー VGA (SVGA) コンピュータ ディスプレイ規格を開発および推進するために、Video Electronics Standards Association (VESA) の設立を発表しました。 Super VGA により、グラフィックス表示解像度は最大 800 × 600 ピクセルとなり、36% 向上しました。[20]

1990年代

Tseng Labs ET4000/W32p

S3 グラフィックス ViRGE

Voodoo3 2000 AGP カード
1991 年、S3 Graphics は S3 86C911 を発表しました。S3 86C911 の設計者は、約束されたパフォーマンスの向上を示すものとして、ポルシェ 911 にちなんで命名しました。[21] 86C911 はさまざまな模倣品を生み出しました。1995 年までに、すべての主要な PC グラフィックス チップ メーカーが自社のチップに 2D アクセラレーションのサポートを追加しました。[22]固定機能の Windows アクセラレータは、Windows のパフォーマンスにおいて高価な汎用グラフィックス コプロセッサを上回り、そのようなコプロセッサは PC 市場から消えていきました。

1990 年代を通じて、2D GUI アクセラレーションが進化しました。製造能力が向上するにつれて、グラフィックス チップの統合レベルも向上しました。 Microsoft の Windows 3.x 用 WinG グラフィックス ライブラリや、Windows 95 以降の 2D ゲームのハードウェア アクセラレーション用の新しい DirectDraw インターフェイスなど、さまざまなタスク用の追加のアプリケーション プログラミング インターフェイス (API) が登場しました。

1990 年代初頭から中頃にかけて、リアルタイム 3D グラフィックスはアーケード、コンピュータ、コンソール ゲームでますます一般的になり、ハードウェア アクセラレーションによる 3D グラフィックスに対する一般の需要が高まりました。量販向け 3D グラフィックス ハードウェアの初期の例は、Sega Model 1、Namco System 22、Sega Model 2 などのアーケード システム ボードや、Saturn、PlayStation、Nintendo 64 などの第 5 世代ビデオ ゲーム コンソールに見られます。1993 年の Sega Model 2 や SGI Onyx ベースの Namco Magic Edge Hornet Simulator などのアーケード システムは、登場する数年前からハードウェア T&L (変換、クリッピング、ライティング) が可能でした。コンシューマー向けグラフィックス カードに使用されます。[23][24]もう 1 つの初期の例は、Super FX チップです。これは、一部の SNES ゲーム、特に Doom や Star Fox で使用されている RISC ベースのオンカートリッジ グラフィックス チップです。一部のシステムでは、変換を加速するために DSP を使用していました。 Sega Model 2 アーケード システムに取り組んだ富士通 [25] は、1995 年に家庭用コンピュータで使用するための単一の LSI ソリューションに T&L を統合する取り組みを開始し [26]、パーソナル コンピュータ用の最初の 3D ジオメトリ プロセッサである Fujitsu Pinolite は 1997 年にリリースされました [27]。家庭用ビデオゲーム機における最初のハードウェア T&L GPU は、1996 年にリリースされた Nintendo 64 のリアリティ コプロセッサでした。 1997 年に、三菱は、ワークステーションと Windows NT デスクトップ向けに、変換とライティングが可能な GPU である 3Dpro/2MP をリリースしました。[29]、ATi は、1997 年にリリースした FireGL 4000 グラフィックス カードにそれを使用しました。[30]

「GPU」という用語は、1994 年に発売された PlayStation ビデオ ゲーム コンソールの 32 ビット ソニー GPU (東芝が設計) を参照してソニーによって造語されました [31]。

PC の世界では、S3 ViRGE、ATI Rage、Matrox Mystique など、低コスト 3D グラフィックス チップの試みが失敗に終わったことが有名です。これらのチップは本質的に、3D 機能が追加された前世代の 2D アクセラレータでした。実装を容易にし、コストを最小限に抑えるために、多くは前世代のチップとピン互換性がありました。当初、3D グラフィックスは、PowerVR や 3dfx Voodoo などの 3D 機能の高速化専用のディスクリート ボード (2D グラフィカル ユーザー インターフェイス (GUI) アクセラレーションが完全に欠如している) でのみ可能でした。しかし、製造技術が進歩し続けるにつれて、ビデオ、2D GUI アクセラレーション、および 3D 機能がすべて 1 つのチップに統合されました。 Rendition の Verite チップセットは、これを最初に成功させたチップセットの 1 つです。 1997 年、Rendition は Hercules および富士通と「スリラー コンスピラシー」プロジェクトで協力しました。このプロジェクトでは、富士通 FXG-1 Pinolite ジオメトリ プロセッサと Vérité V2200 コアを組み合わせて、Nvidia の GeForce 256 が登場する数年前に完全な T&L エンジンを備えたグラフィックス カードを作成しました。このカードは、システムの CPU にかかる負荷を軽減するように設計されていましたが、市場に投入されることはありませんでした。[要出典] NVIDIA RIVA 128 は、チップ上に 3D プロセッシング ユニットと 2D プロセッシング ユニットを統合した最初の消費者向け GPU の 1 つでした。

OpenGL は、3D ラスタライゼーションのための独自のハードウェア サポートを備えたプロフェッショナル グラフィックス API として 90 年代初頭に SGI によって導入されました。 1994 年に Microsoft は、ジュラシック パーク、ターミネーター 2、タイタニックなどの初期の CGI 映画のヒット作に使用された有力な CGI 映画制作ツールである Softimage を買収しました。この契約により、SGI との戦略的関係と、SGI の OpenGL ライブラリの商用ライセンスが得られ、Microsoft は API を Windows NT OS に移植できるようになりましたが、次期リリースの Windows '95 には移植できませんでした。当時はほとんど知られていなかったが、SGI は Unix から次期 Windows NT OS に移行するために Microsoft と契約を結んでいたが、1995 年に署名されたこの契約は 1998 年まで公に発表されなかった。その間、Microsoft は SGI と緊密に協力して OpenGL を Windows NT に移植した。当時の OpenGL には、より高レベルの 3D テクスチャリングとライティング機能のサポートに基づいて競合するハードウェア アクセラレータ用の標準ドライバー モデルがありませんでした。 1994 年に Microsoft は、次期 Windows '95 コンシューマ OS での DirectX 1.0 とゲームのサポートを発表し、'95 年に Microsoft は英国に本拠を置く Rendermorphics Ltd の買収とコンシューマ 3D グラフィックスを高速化するための Direct3D ドライバ モデルを発表しました。 Direct3D ドライバー モデルは、1996 年に DirectX 2.0 とともに出荷されました。これには、3D チップ メーカーが 3D テクスチャ、ライティング、Z バッファリングのサポートを競うための標準と仕様が含まれていました。後に AMD に買収される ATI は、最初の Direct3D GPU の開発を開始しました。 Nvidia は、1996 年に失敗した Sega との契約からすぐに方向転換して、Direct3D のサポートを積極的に採用しました。この時代、Microsoft は社内の Direct3D チームと OpenGL チームを統合し、SGI と緊密に連携して産業用と民生用の両方の 3D グラフィックス ハードウェア アクセラレータのドライバ標準を統一しました。 Microsoft は、3D チップ メーカー向けに、Direct3D と OpenGL の両方で動作する 3D ハードウェアとドライバーをテストする「Meltdowns」と呼ばれる年次イベントを開催しました。 3D アクセラレータ カードが単純なラスタライザを超えて、ハードウェア アクセラレーションによるテクスチャ マッピング、ライティング、Z バッファリング、コンピューティングのサポートにより最新の GPU が作成された、より強力な汎用プロセッサへと移行したのは、3D 標準に対する Microsoft の影響力が強かったこの時期でした。この期間中に、Direct3D および OpenGL ドライバーの標準化を担当した同じ Microsoft チームが、Talisman と呼ばれる独自の Microsoft 3D チップ設計を導入しました。この時代の詳細は、ラッセル・デマリア著『Game of X』v.1 および v.2、マイク・ドラモンド著『帝国の反逆者』、ディーン・タカハシ著『Xbox を開く』、デイビッド・クシュナー著『マスターズ オブ ドゥーム』などの書籍に詳しく記載されています。 Nvidia GeForce 256 (NV10 としても知られる) は、ハードウェア アクセラレーションによる T&L を備えた最初のコンシューマー レベルのカードでした。 OpenGL API はテクスチャ マッピングとライティングのソフトウェア サポートを提供しましたが、これらの機能のための最初の 3D ハードウェア アクセラレーションは、最初の Direct3D アクセラレーション コンシューマ GPU とともに提供されました。

2000年代
Nvidia は、プログラマブル シェーディングが可能なチップである GeForce 3 を最初に製造しました。各ピクセルは、入力として追加の画像テクスチャを含めることができる短いプログラムによって処理できるようになり、各幾何学的頂点も同様に、スクリーンに投影される前に短いプログラムによって処理できるようになりました。 Xbox コンソールで使用されるこのチップは、ハードウェア アクセラレーション頂点処理 (一般に VU0/VU1 と呼ばれる) にカスタム ベクトル ユニットを使用する PlayStation 2 のチップと競合しました。 Xbox で使用されていた初期のシェーダー実行エンジンは汎用ではなく、任意のピクセル コードを実行できませんでした。頂点とピクセルは、独自のリソースを持つ異なるユニットによって処理され、ピクセル シェーダーにはより厳しい制約がありました (頂点よりも高い周波数で実行されるため)。ピクセル シェーディング エンジンは、実際には高度にカスタマイズ可能な機能ブロックに似ており、実際にはプログラムを「実行」しませんでした。頂点シェーディングとピクセル シェーディング間のこうした不一致の多くは、統合シェーダー モデルが登場するまで対処されていませんでした。

2002 年 10 月、ATI Radeon 9700 (R300 としても知られる) の導入により、世界初の Direct3D 9.0 アクセラレータ、ピクセル シェーダ、および頂点シェーダは、ループ処理と長時間の浮動小数点演算を実装できるようになり、すぐに CPU と同じくらい柔軟になり、さらに画像配列操作が桁違いに高速になりました。ピクセル シェーディングは、バンプ マッピングによく使用されます。これにより、オブジェクトに光沢、鈍さ、粗さ、さらには丸く、押し出されたように見えるテクスチャが追加されます。[32]

Nvidia GeForce 8 シリーズと新しい汎用ストリーム処理ユニットの導入により、GPU はより汎用化されたコンピューティング デバイスになりました。並列 GPU は CPU に対する計算の分野に進出しており、GPU コンピューティングまたは GPU 上の汎用コンピューティングの GPGPU と呼ばれる研究サブフィールドは、機械学習[33]、石油探査、科学画像処理、線形代数、[34] 統計、[35] 3D 再構成、およびストック オプションの価格設定など、さまざまな分野で応用されています。 GPGPU は、現在計算シェーダー (CUDA、OpenCL、DirectCompute など) と呼ばれるものの前身であり、アルゴリズムに渡されたデータをテクスチャ マップとして扱い、適切なピクセル シェーダーで三角形または四角形を描画することでアルゴリズムを実行することによって、実際にハードウェアをある程度悪用していました。[説明が必要] スキャン コンバーターなどのユニットが必要のないところで関与しているため (三角形の操作も問題ではありません。呼び出しを除く)、これにはある程度のオーバーヘッドが伴います。ピクセル シェーダ)。[説明が必要]

2007 年に初めて導入された Nvidia の CUDA プラットフォーム [36] は、GPU コンピューティングに広く採用された最も初期のプログラミング モデルでした。 OpenCL は、移植性を重視した GPU と CPU の両方のコード開発を可能にする、Khronos Group によって定義されたオープン スタンダードです。[37] OpenCL ソリューションは Intel、AMD、Nvidia、および ARM によってサポートされており、Evans Data による 2011 年のレポートによると、OpenCL は 2 番目に人気のある HPC ツールとなっています [38]。

2010年代
2010 年、Nvidia は Audi と提携して車のダッシュボードに電力を供給し、Tegra GPU を使用して車のナビゲーションおよびエンターテイメント システムの機能を強化しました [39]。自動車の GPU テクノロジーの進歩は、自動運転技術の進歩に貢献しました。[40] AMD の Radeon HD 6000 シリーズ カードは 2010 年にリリースされ、2011 年に AMD はモバイル デバイス用の 6000M シリーズ ディスクリート GPU をリリースしました [41]。 Nvidia のグラフィックス カードの Kepler シリーズは 2012 年にリリースされ、Nvidia の 600 および 700 シリーズ カードで使用されました。この GPU マイクロアーキテクチャの機能には、消費電力に応じてビデオ カードのクロック速度を調整して増減させるテクノロジである GPU ブーストが含まれています。[42] Kepler マイクロアーキテクチャは 28 nm プロセスで製造されました [要説明]。

PS4 と Xbox One は 2013 年にリリースされました。どちらも AMD の Radeon HD 7850 および 7790 ベースの GPU を使用しています。[43] Nvidia の Kepler GPU シリーズの後に、同じプロセスで製造された Maxwell ラインが続きました。 Nvidia の 28 nm チップは、28 nm プロセスを使用して台湾の TSMC によって製造されました。過去の 40 nm テクノロジーと比較して、この製造プロセスにより、消費電力を低減しながら性能を 20% 向上させることができました [44] [45]。仮想現実ヘッドセットには高いシステム要件があります。メーカーは発売時に GTX 970 および R9 290X 以上を推奨していました。[46][47] Pascal マイクロアーキテクチャに基づくカードは 2016 年にリリースされました。GeForce 10 シリーズのカードは、この世代のグラフィックス カードです。これらは、以前のマイクロアーキテクチャを改良した 16 nm 製造プロセスを使用して製造されています。[48] Nvidia は、新しい Volta アーキテクチャの下で 1 つの非コンシューマ カード、Titan V をリリースしました。Pascal のハイエンド カードである Titan XP からの変更点には、CUDA コア数の増加、Tensor コア、および HBM2 の追加が含まれます。 Tensor コアは深層学習用に設計されているのに対し、高帯域幅メモリはオンダイのスタックされた低クロック メモリであり、非常に広いメモリ バスを提供します。 Titan V がゲーム カードではないことを強調するために、Nvidia はコンシューマ ゲーム カードに付加されている「GeForce GTX」というサフィックスを削除しました。

2018 年、Nvidia は GPU にレイ トレーシング コアを追加し、照明効果のパフォーマンスを向上させた RTX 20 シリーズ GPU を発売しました [49]。 AMD の Polaris 11 GPU および Polaris 10 GPU は、14 nm プロセスで製造されています。これらのリリースにより、AMD ビデオ カードのワットあたりのパフォーマンスが大幅に向上しました。[50] AMDはまた、NvidiaのハイエンドPascalカードの競合相手として、ハイエンド市場向けにVega GPUシリーズもリリースしており、これもTitan Vと同様にHBM2を搭載しています。

2019 年、AMD は Graphics Core Next (GCN) マイクロアーキテクチャ/命令セットの後継をリリースしました。 RDNA と呼ばれる、これを搭載した最初の製品は、Radeon RX 5000 シリーズのビデオ カードでした。[51]

同社は、RDNA マイクロアーキテクチャの後継がインクリメンタル (別名リフレッシュ) になると発表しました。 AMDは、ハードウェアアクセラレーションによるレイトレーシングをサポートするRDNA 2グラフィックスカードであるRadeon RX 6000シリーズを発表した[52]。 2020 年後半に発売されたこの製品シリーズは、RX 6800、RX 6800 XT、RX 6900 XT で構成されていました。[53][54] Navi 22 をベースにした RX 6700 XT は 2021 年初頭に発売されました [55]。

PlayStation 5 と Xbox シリーズ X およびシリーズ S は 2020 年にリリースされました。どちらも RDNA 2 マイクロアーキテクチャに基づく GPU を使用しており、段階的な改善と各システムの実装で異なる GPU 構成が採用されています。[56][57][58]

Intel は 1990 年代後半に初めて GPU 市場に参入しましたが、当時の競合他社に比べて精彩のない 3D アクセラレータを製造していました。ハイエンド メーカーである Nvidia や ATI/AMD と競争しようとするのではなく、Intel グラフィックス テクノロジー GPU をマザーボード チップセットに統合し始め、Pentium III 用 Intel 810 から始まり、その後 CPU に統合されました。 2009 年の Intel Atom 'Pineview' ラップトップ プロセッサから始まり、2010 年には第 1 世代の Intel Core ラインのデスクトップ プロセッサと最新の Pentium および Celeron が開発されました。 Intel CPU を搭載したコンピュータの大部分もこの組み込みグラフィックス プロセッサを備えていたため、この結果、名目上の市場シェアが大きくなりました。これらは一般に、ディスクリート プロセッサに比べてパフォーマンスが遅れています。 Intelは2022年にArcシリーズでディスクリートGPU市場に再参入し、当時のGeForce 30シリーズやRadeon 6000シリーズのカードと競争力のある価格で競合した[要出典]。

2020年代
参照: AI アクセラレータ
2020 年代には、大規模な言語モデルに必要な膨大なデータセットでのニューラル ネットワークのトレーニングなど、恥ずかしいほどの並列問題を伴う計算に GPU がますます使用されるようになりました。一部の最新のワークステーションの GPU に搭載された特殊な処理コアは、4×4 行列の乗算と除算を使用して FLOPS パフォーマンスが大幅に向上するため、ディープ ラーニング専用になっており、一部のアプリケーションではハードウェア パフォーマンスが最大 128 TFLOPS になります [59]。これらの Tensor コアは、消費者向けカードにも搭載される予定です。[更新が必要][60]

GPU 企業
多くの企業がさまざまなブランド名で GPU を製造しています。 2009 年には、[要更新] Intel、Nvidia、AMD/ATI が市場シェアのリーダーであり、それぞれ 49.4%、27.8%、20.6% の市場シェアを獲得しました。さらに、Matrox[61] は GPU を製造しています。最新のスマートフォンでは、主に Qualcomm の Adreno GPU、Imagination Technologies の PowerVR GPU、ARM の Mali GPU が使用されています。

計算関数
最新の GPU は従来、トランジスタの大部分を 3D コンピュータ グラフィックスに関連する計算に使用してきました。 3D ハードウェアに加えて、今日の GPU には、基本的な 2D アクセラレーションとフレームバッファ機能 (通常は VGA 互換モード) が含まれています。 AMD/ATI HD5000 ～ HD7000 などの新しいカードには専用の 2D アクセラレーションがありません。 3D ハードウェアによってエミュレートされます。 GPU は当初、テクスチャ マッピングとポリゴンのレンダリングというメモリを大量に消費する作業を高速化するために使用されました。その後、頂点の回転や異なる座標系への変換などの幾何学的計算を高速化するユニット[要説明]が追加されました。 GPU の最近の開発には、CPU でサポートされているのと同じ操作の多くで頂点とテクスチャを操作できるプログラマブル シェーダのサポート、エイリアシングを低減するためのオーバーサンプリングと補間技術、および非常に高精度の色空間が含まれます。

GPU 構造のいくつかの要因は、半導体デバイス製造におけるコネクタ経路のサイズ、クロック信号周波数、さまざまなオンチップ メモリ キャッシュの数とサイズなど、リアルタイム レンダリング用のカードのパフォーマンスに影響します。パフォーマンスは、NVidia GPU の場合はストリーミング マルチプロセッサ (SM)、AMD GPU の場合はコンピューティング ユニット (CU)、または Intel ディスクリート GPU の場合は Xe コアの数によっても影響されます。これらは、コア計算を実行する GPU チップ内のコア オンシリコン プロセッサ ユニットの数を表し、通常は GPU 上の他の SM/CU と並行して動作します。 GPU のパフォーマンスは通常、1 秒あたりの浮動小数点演算 (FLOPS) で測定されます。 2010 年代と 2020 年代の GPU は通常、テラフロップス (TFLOPS) 単位で測定されるパフォーマンスを提供します。他の要因が実際の表示速度に影響を与える可能性があるため、これは推定パフォーマンス測定値です。[62]

GPU で高速化されたビデオのデコーディングとエンコーディング

ATI HD5470 GPU (上、銅製ヒートパイプが取り付けられている) は、AVC および VC-1 ビデオ フォーマットのデコードを可能にする UVD 2.1 を備えています。
1995 年以降に製造されたほとんどの GPU は、デジタル ビデオ再生に重要な YUV カラー スペースとハードウェア オーバーレイをサポートしており、2000 年以降に製造された多くの GPU は動き補償や iDCT などの MPEG プリミティブもサポートしています。このハードウェア アクセラレーションによるビデオ デコードでは、ビデオ デコード プロセスとビデオの後処理の一部が GPU ハードウェアにオフロードされ、一般に「GPU アクセラレーション ビデオ デコーディング」、「GPU 支援ビデオ デコーディング」、「GPU ハードウェア アクセラレーション ビデオ デコーディング」、または「GPU ハードウェア 支援ビデオ デコーディング」と呼ばれます。

最近のグラフィックス カードはカード上で高解像度ビデオをデコードし、中央処理装置の負荷を軽減します。 GPU アクセラレーションによるビデオ デコーディングの最も一般的な API は、Microsoft Windows オペレーティング システムの場合は DxVA、Linux ベースおよび UNIX 系のオペレーティング システムの場合は VDPAU、VAAPI、XvMC、および XvBA です。 XvMC を除くすべては、MPEG-1、MPEG-2、MPEG-4 ASP (MPEG-4 Part 2)、MPEG-4 AVC (H.264 / DivX 6)、VC-1、WMV3/WMV9、Xvid / OpenDivX (DivX 4)、および DivX 5 コーデックでエンコードされたビデオをデコードできますが、XvMC は MPEG-1 および DivX 5 コーデックのみをデコードできます。 MPEG-2。

専用のハードウェア ビデオ デコードおよびエンコード ソリューションがいくつかあります。

高速化できるビデオデコードプロセス
最新の GPU ハードウェアによって高速化できるビデオ デコード プロセスは次のとおりです。

動き補償（mocomp）
逆離散コサイン変換 (iDCT)
逆テレシネ 3:2 および 2:2 プルダウン補正
逆修正離散コサイン変換 (iMDCT)
ループ内デブロッキングフィルター
フレーム内予測
逆量子化 (IQ)
可変長デコード (VLD)、一般的にはスライスレベルのアクセラレーションとして知られています
時空間デインターレースと自動インターレース/プログレッシブ ソース検出
ビットストリーム処理 (コンテキスト適応型可変長コーディング/コンテキスト適応型バイナリ算術コーディング) と完璧なピクセル位置決め
これらの操作は、ビデオ編集、エンコード、トランスコーディングにも応用できます。

2DグラフィックスAPI
初期の GPU は、GDI や DirectDraw などの 2D アクセラレーション用の 1 つ以上の 2D グラフィックス API をサポートしている場合があります。[63]

3DグラフィックスAPI
GPU は、DirectX、Metal、OpenGL、OpenGL ES、Vulkan などの 1 つ以上の 3D グラフィックス API をサポートできます。

