{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promptfoo: custom code graders\n",
    "\n",
    "**Note: このレッスンは関連コードファイルを含むフォルダ内にあります。実際に手元で実行しながら進めたい場合は、フォルダ全体をダウンロードしてください。**\n",
    "\n",
    "これまで、promptfoo の組み込み採点（grader）である `exact-match` や `contains-all` のようなものを使ってきました。これらは便利ですが、promptfoo では **より特定の採点タスク向けに、独自の採点ロジック（カスタムグレーダ）** を書くこともできます。\n",
    "\n",
    "それを示すために、次のシンプルなプロンプトテンプレートを使います：\n",
    "\n",
    "> Write a short paragraph about {{topic}}. Make sure you mention {{topic}} exactly {{count}} times, no more or fewer.\n",
    "\n",
    "`{{topic}}` と `{{count}}` に例えば `\"tweezers\"` と `7` を入れると、次のようなプロンプトになります：\n",
    "\n",
    "> Write a short paragraph about tweezers. Make sure you mention tweezers exactly 7 times, no more or fewer.\n",
    "\n",
    "これを採点するには、モデル出力に \"tweezers\" がちょうど7回出現することをチェックするカスタムロジックが必要です。\n",
    "\n",
    "例えば次のプロンプト：\n",
    "\n",
    "> Write a short paragraph about sheep. Make sure you mention sheep exactly 3 times, no more or fewer.\n",
    "\n",
    "では、モデル出力に \"sheep\" がちょうど3回含まれていることを確認する採点ロジックが必要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing promptfoo\n",
    "\n",
    "いつも通り、まずは次のコマンドで promptfoo を初期化します：\n",
    "\n",
    "```bash\n",
    "npx promptfoo@latest init\n",
    "```\n",
    "\n",
    "これまでと同様に `promptfooconfig.yaml` が作成されます。既存の内容は削除して構いません。\n",
    "\n",
    "次にプロバイダを設定します。`promptfooconfig.yaml` に次を追加してください：\n",
    "\n",
    "```yaml\n",
    "description: Count mentions\n",
    "\n",
    "providers:\n",
    "  - anthropic:messages:claude-3-haiku-20240307\n",
    "  - anthropic:messages:claude-3-5-sonnet-20240620\n",
    "```\n",
    "\n",
    "これにより、Claude 3 Haiku と Claude 3.5 Sonnet の両方で評価を回し、このタスクでの性能を比較できます。\n",
    "\n",
    "`ANTHROPIC_API_KEY` 環境変数が設定されていることを確認してください。ターミナルで次のように設定できます：\n",
    "\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our prompts\n",
    "\n",
    "これまでは Python ファイルに関数としてプロンプトを書く方法を推奨してきましたが、promptfoo には他にもいくつかの指定方法があります。最もシンプルなのは、YAMLファイルにプロンプト本文を直接書く方法です。\n",
    "\n",
    "ここではこのインライン方式を試します。`promptfooconfig.yaml` を次のように更新してください：\n",
    "\n",
    "```yaml\n",
    "description: Count mentions\n",
    "prompts:\n",
    "  - >-\n",
    "    {{topic}}について短い段落を書いてください。{{topic}}をちょうど{{count}}回、それ以上でもそれ以下でもなく言及してください。出力では小文字のみを使用してください。\n",
    "providers:\n",
    "  - anthropic:messages:claude-3-haiku-20240307\n",
    "  - anthropic:messages:claude-3-5-sonnet-20240620\n",
    "```\n",
    "\n",
    "`prompts` フィールドに、テキストプロンプトを直接書いている点に注目してください。また `{{topic}}` と `{{count}}` のように二重波括弧を使っています。これは Nunjucks のテンプレート構文で、この後重要になります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing our test cases\n",
    "\n",
    "以前のレッスンでは CSV にテストケースと採点ロジックを書きました。繰り返しになりますが、promptfoo は非常に柔軟で、テストの指定方法も複数あります。\n",
    "\n",
    "ここでは、テストケースを YAML 設定ファイル内に直接書きます。`promptfooconfig.yaml` を次のようにしてください：\n",
    "\n",
    "```yaml\n",
    "description: Count mentions\n",
    "prompts:\n",
    "  - >-\n",
    "    {{topic}}について短い段落を書いてください。{{topic}}をちょうど{{count}}回、それ以上でもそれ以下でもなく言及してください。出力では小文字のみを使用してください。\n",
    "providers:\n",
    "  - anthropic:messages:claude-3-haiku-20240307\n",
    "  - anthropic:messages:claude-3-5-sonnet-20240620\n",
    "tests:\n",
    "  - vars:\n",
    "      topic: sheep\n",
    "      count: 3\n",
    "  - vars:\n",
    "      topic: fowl\n",
    "      count: 2\n",
    "  - vars:\n",
    "      topic: gallows\n",
    "      count: 4\n",
    "  - vars:\n",
    "      topic: tweezers\n",
    "      count: 7\n",
    "  - vars:\n",
    "      topic: jeans\n",
    "      count: 6\n",
    "```\n",
    "\n",
    "末尾で5つのテストケースを定義しており、それぞれ `topic` と `count` が異なります。promptfoo は各テストを自動実行し、テンプレート内の `{{topic}}` と `{{count}}` を置換します。\n",
    "\n",
    "まだ採点ロジックはありませんが、まずは変数が正しく埋め込まれているか確認するために評価を実行できます。\n",
    "\n",
    "評価はこれまでと同じコマンドです：\n",
    "\n",
    "```bash\n",
    "npx promptfoo@latest eval\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力例は次のとおりです：\n",
    "\n",
    "![initial_eval_output.png](../images/initial_eval_output.png)\n",
    "\n",
    "1行だけ拡大すると、モデル出力は概ね良さそうに見えます。この例では `{{topic}}` が \"sheep\" になっており、出力も羊についての段落になっています。\n",
    "\n",
    "![single_row-2.png](../images/single_row.png)\n",
    "\n",
    "あとは、出力がトピックを指定回数ちょうど含むかをチェックするカスタム採点ロジックを実装するだけです。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Adding a custom grader function\n",
    "\n",
    "promptfoo では Python で独自の採点関数を書けます。この例では、モデル出力に指定トピックが指定回数ちょうど出現することを保証する関数を作ります。\n",
    "\n",
    "`count.py` という新しい Python ファイルを作り、次の関数を追加します：\n",
    "\n",
    "```py\n",
    "import re\n",
    "\n",
    "def get_assert(output, context):\n",
    "    topic = context[\"vars\"][\"topic\"]\n",
    "    goal_count = int(context[\"vars\"][\"count\"])\n",
    "    pattern = fr'(^|\\s)\b{re.escape(topic)}\b'\n",
    "\n",
    "    actual_count = len(re.findall(pattern, output.lower()))\n",
    "\n",
    "    pass_result = goal_count == actual_count\n",
    "\n",
    "    result = {\n",
    "        \"pass\": pass_result,\n",
    "        \"score\": 1 if pass_result else 0,\n",
    "        \"reason\": f\"Expected {topic} to appear {goal_count} times. Actual: {actual_count}\",\n",
    "    }\n",
    "    return result\n",
    "```\n",
    "\n",
    "上のコードの動きを説明します。promptfoo はファイル内の `get_assert` という関数を自動的に探し、次の2引数を渡します：\n",
    "\n",
    "- あるモデルの出力（output）\n",
    "- その出力を生成した変数やプロンプトを含む `context` 辞書\n",
    "\n",
    "promptfoo は、関数の戻り値として次のいずれかを受け付けます：\n",
    "- bool（合否）\n",
    "- float（スコア）\n",
    "- GradingResult 辞書\n",
    "\n",
    "ここでは GradingResult 辞書を返します。これには次のプロパティが必要です：\n",
    "\n",
    "- `pass_`：boolean\n",
    "- `score`：float\n",
    "- `reason`：説明文（string）\n",
    "\n",
    "この関数では、`context` から topic と count を取り出し、正規表現でトピック出現回数を数え、結果を `result` として返しています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グレーダを定義できたので、次は promptfoo にそれを使うよう伝えます。`promptfooconfig.yaml` を次のように更新してください：\n",
    "\n",
    "```yaml\n",
    "description: Count mentions\n",
    "prompts:\n",
    "  - >-\n",
    "    {{topic}}について短い段落を書いてください。{{topic}}をちょうど{{count}}回、それ以上でもそれ以下でもなく言及してください。出力では小文字のみを使用してください。\n",
    "providers:\n",
    "  - anthropic:messages:claude-3-haiku-20240307\n",
    "  - anthropic:messages:claude-3-5-sonnet-20240620\n",
    "defaultTest:\n",
    "  assert:\n",
    "    - type: python\n",
    "      value: file://count.py\n",
    "tests:\n",
    "  - vars:\n",
    "      topic: sheep\n",
    "      count: 3\n",
    "  - vars:\n",
    "      topic: fowl\n",
    "      count: 2\n",
    "  - vars:\n",
    "      topic: gallows\n",
    "      count: 4\n",
    "  - vars:\n",
    "      topic: tweezers\n",
    "      count: 7\n",
    "  - vars:\n",
    "      topic: jeans\n",
    "      count: 6\n",
    "```\n",
    "\n",
    "`defaultTest` は、各テストを実行する際に `count.py` の Python グレーダを使うことを指定しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the evaluation\n",
    "\n",
    "評価を実行するには、これまでと同じコマンドを使います：\n",
    "\n",
    "```bash\n",
    "npx promptfoo@latest eval\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価を実行すると、次のような結果になります：\n",
    "\n",
    "![final_eval.png](../images/final_eval.png)\n",
    "\n",
    "Webインターフェースを開くには次を実行します：\n",
    "\n",
    "```bash\n",
    "npx promptfoo@latest view\n",
    "```\n",
    "\n",
    "![final_view.png](../images/final_view.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このタスクでは、Claude 3.5 が 100% で、Claude 3 Haiku は 20% でした。結果を確認するには、虫眼鏡アイコンをクリックして入力プロンプトと対応する出力を表示します。\n",
    "\n",
    "Claude 3 Haiku の誤った出力例：\n",
    "\n",
    "![tweezers_haiku_closeup.png](../images/tweezers_haiku_closeup.png)\n",
    "\n",
    "Claude 3.5 Sonnet の正しい出力例：\n",
    "\n",
    "![tweezers_sonnet_closeup.png](../images/tweezers_sonnet_closeup.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この評価自体は少しふざけた題材ですが、目的は「カスタムの Python 採点ロジックを定義する手順」を示すことです。promptfoo の組み込みアサーションとカスタムグレーダ関数を組み合わせれば、ほぼ任意のコード採点評価を作れます。\n",
    "\n",
    "次のレッスンでは、promptfoo におけるモデル採点（model-graded）の評価を学びます。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
